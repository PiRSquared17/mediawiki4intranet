Index: skins/common/shared.css
===================================================================
--- skins/common/shared.css	(revision 82604)
+++ skins/common/shared.css	(working copy)
@@ -519,6 +519,8 @@
 	font-size: 90%;
 }
 
+.addpages div { display: inline-block; text-align: right; vertical-align: top; padding-right: 8px; }
+
 /* (show/hide) revision deletion links */
 span.mw-revdelundel-link,
 strong.mw-revdelundel-link {
Index: includes/filerepo/LocalFile.php
===================================================================
--- includes/filerepo/LocalFile.php	(revision 82604)
+++ includes/filerepo/LocalFile.php	(working copy)
@@ -851,6 +851,66 @@
 	}
 
 	/**
+	 * Upload a file directly into archive. Generally for Special:Import
+	 */
+	function uploadIntoArchive( $srcPath, $comment, $pageText, $flags = 0, $props = false, $timestamp = false )
+	{
+		$this->lock();
+		$dstName = gmdate( 'YmdHis', wfTimestamp( TS_UNIX, $timestamp ) ) . '!' . $this->getName();
+		$status = $this->publish( $srcPath, $flags, $dstName );
+		if ( $status->ok ) {
+			if ( !$this->recordOldUpload( $dstName, $comment, $pageText, $props, $timestamp ) ) {
+				$status->fatal( 'filenotfound', $srcPath );
+			}
+		}
+		$this->unlock();
+		return $status;
+	}
+
+	/**
+	 * Record a file upload in the upload log and the oldimage table
+	 */
+	function recordOldUpload( $dstName, $comment, $pageText, $props = false, $timestamp = false )
+	{
+		global $wgUser;
+
+		$dbw = $this->repo->getMasterDB();
+
+		$dstPath = $this->repo->getZonePath('public') . '/archive/' . $this->getHashPath() . $dstName;
+		$props = self::getPropsFromPath( $dstPath );
+		if (!$props['fileExists'])
+			return false;
+
+		$props['timestamp'] = wfTimestamp( TS_MW, $timestamp );
+		list($props['major_mime'], $props['minor_mime']) =
+			self::splitMime( "{$props['major_mime']}/{$props['minor_mime']}" );
+
+		$dbw->insert( 'oldimage',
+			array(
+				'oi_name'         => $this->getName(),
+				'oi_archive_name' => $dstName,
+				'oi_size'         => $props['size'],
+				'oi_width'        => intval($props['width']),
+				'oi_height'       => intval($props['height']),
+				'oi_bits'         => $props['bits'],
+				'oi_timestamp'    => $props['timestamp'],
+				'oi_description'  => $comment,
+				'oi_user'         => $wgUser->getId(),
+				'oi_user_text'    => $wgUser->getName(),
+				'oi_metadata'     => $props['metadata'],
+				'oi_media_type'   => $props['media_type'],
+				'oi_major_mime'   => $props['major_mime'],
+				'oi_minor_mime'   => $props['minor_mime'],
+				'oi_sha1'         => $props['sha1'],
+			), __METHOD__
+		);
+
+		$dbw->immediateCommit();
+
+		return true;
+	}
+
+	/**
 	 * Record a file upload in the upload log and the image table
 	 */
 	function recordUpload2( $oldver, $comment, $pageText, $props = false, $timestamp = false, $user = null )
@@ -1038,16 +1098,22 @@
 	 *
 	 * @param $srcPath String: local filesystem path to the source image
 	 * @param $flags Integer: a bitwise combination of:
-	 *     File::DELETE_SOURCE    Delete the source file, i.e. move
-	 *         rather than copy
+	 *     File::DELETE_SOURCE       Delete the source file, i.e. move rather than copy
+	 * @param string $dstName Local wanted path (for example some archive
+	 *        path to publish image into the archive directly)
 	 * @return FileRepoStatus object. On success, the value member contains the
 	 *     archive name, or an empty string if it was a new file.
 	 */
-	function publish( $srcPath, $flags = 0 ) {
+	function publish( $srcPath, $flags = 0, $dstName = NULL ) {
 		$this->lock();
 
-		$dstRel = $this->getRel();
-		$archiveName = gmdate( 'YmdHis' ) . '!' . $this->getName();
+		if (!$dstName)
+			$dstRel = $this->getRel();
+		else
+			$dstRel = 'archive/' . $this->getHashPath() . $dstName;
+		/* Original gmdate( 'YmdHis' ) is not corrent AT ALL! */
+		/* It gives an inconsistency: file name has one timestamp and database row has another. */
+		$archiveName = gmdate( 'YmdHis', wfTimestamp( TS_UNIX, $this->getTimestamp() ) ) . '!'. $this->getName();
 		$archiveRel = 'archive/' . $this->getHashPath() . $archiveName;
 		$flags = $flags & File::DELETE_SOURCE ? LocalRepo::DELETE_SOURCE : 0;
 		$status = $this->repo->publish( $srcPath, $dstRel, $archiveRel, $flags );
Index: includes/Export.php
===================================================================
--- includes/Export.php	(revision 82604)
+++ includes/Export.php	(working copy)
@@ -3,6 +3,7 @@
  * Base classes for dumps and export
  *
  * Copyright © 2003, 2005, 2006 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  * http://www.mediawiki.org/
  *
  * This program is free software; you can redistribute it and/or modify
@@ -34,7 +35,8 @@
 	var $list_authors = false ; # Return distinct author list (when not returning full history)
 	var $author_list = "" ;
 
-	var $dumpUploads = false;
+	var $dumpUploads = false;   # Dump uploaded files into the export file
+	var $selfContained = false; # Make export file self-contained (multipart/related)
 
 	const FULL = 1;
 	const CURRENT = 2;
@@ -85,6 +87,7 @@
 	}
 
 	public function openStream() {
+		$this->writer->multipart = $this->dumpUploads && $this->selfContained;
 		$output = $this->writer->openStream();
 		$this->sink->writeOpenStream( $output );
 	}
@@ -92,6 +95,9 @@
 	public function closeStream() {
 		$output = $this->writer->closeStream();
 		$this->sink->writeCloseStream( $output );
+		/* Dump $this->writer->binaries into multipart/related */
+		while ($part = $this->writer->nextPart())
+			$this->sink->writePart($part);
 	}
 
 	/**
@@ -313,7 +319,8 @@
 				if( isset( $last ) ) {
 					$output = '';
 					if( $this->dumpUploads ) {
-						$output .= $this->writer->writeUploads( $last );
+						$output .= $this->writer->writeUploads( $last,
+							$this->history == WikiExporter::CURRENT ? 1 : null );
 					}
 					$output .= $this->writer->closePage();
 					$this->sink->writeClosePage( $output );
@@ -328,7 +335,8 @@
 		if( isset( $last ) ) {
 			$output = '';
 			if( $this->dumpUploads ) {
-				$output .= $this->writer->writeUploads( $last );
+				$output .= $this->writer->writeUploads( $last,
+					$this->history == WikiExporter::CURRENT ? 1 : null );
 			}
 			$output .= $this->author_list;
 			$output .= $this->writer->closePage();
@@ -349,6 +357,12 @@
  */
 class XmlDumpWriter {
 
+	var $boundary;
+	var $binaries;
+	var $multipart;
+
+	var $currentpart;
+
 	/**
 	 * Returns the export schema version.
 	 * @return string
@@ -370,7 +384,15 @@
 	function openStream() {
 		global $wgLanguageCode;
 		$ver = $this->schemaVersion();
-		return Xml::element( 'mediawiki', array(
+		$mp = '';
+		if ($this->multipart)
+		{
+			$this->boundary = '--'.time();
+			$this->binaries = array();
+			$mp = "Content-Type: multipart/related; boundary=".$this->boundary."\n".$this->boundary."\nContent-Type: text/xml\nContent-ID: Revisions\n\n";
+		}
+		return $mp . "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n" .
+			Xml::element( 'mediawiki', array(
 			'xmlns'              => "http://www.mediawiki.org/xml/export-$ver/",
 			'xmlns:xsi'          => "http://www.w3.org/2001/XMLSchema-instance",
 			'xsi:schemaLocation' => "http://www.mediawiki.org/xml/export-$ver/ " .
@@ -437,6 +459,38 @@
 		return "</mediawiki>\n";
 	}
 
+	function nextPart()
+	{
+		$data = '';
+		if ( !$this->currentpart )
+		{
+			if ( !$this->multipart || !count( $this->binaries ) )
+				return '';
+			list( $name ) = array_keys( $this->binaries );
+			$filename = $this->binaries[ $name ];
+			unset( $this->binaries[ $name ] );
+			$fp = @fopen( $filename, "rb" );
+			if ( !$fp )
+				return $this->nextPart();
+			$this->currentpart = array(
+				'name' => $name,
+				'filename' => $filename,
+				'fp' => $fp,
+			);
+			$data = $this->boundary.
+				"\nContent-Type: application/binary\n" .
+				"Content-Transfer-Encoding: Little-Endian\n" .
+				"Content-ID: $name\n" .
+				"Content-Length: ".filesize($filename)."\n\n";
+		}
+		$data .= @fread( $this->currentpart['fp'], 1048576 );
+		if ( @feof( $this->currentpart['fp'] ) )
+		{
+			@fclose( $this->currentpart['fp'] );
+			$this->currentpart = NULL;
+		}
+		return $data;
+	}
 
 	/**
 	 * Opens a <page> section on the output stream, with data
@@ -595,12 +649,12 @@
 	/**
 	 * Warning! This data is potentially inconsistent. :(
 	 */
-	function writeUploads( $row ) {
+	function writeUploads( $row, $limit = null ) {
 		if( $row->page_namespace == NS_IMAGE ) {
 			$img = wfFindFile( $row->page_title );
 			if( $img ) {
 				$out = '';
-				foreach( array_reverse( $img->getHistory() ) as $ver ) {
+				foreach( $img->getHistory( $limit ? $limit-1 : NULL ) as $ver ) {
 					$out .= $this->writeUpload( $ver );
 				}
 				$out .= $this->writeUpload( $img );
@@ -611,13 +665,22 @@
 	}
 
 	function writeUpload( $file ) {
+		if ( !$file->exists() )
+			return "";
+		if ( $this->multipart )
+		{
+			$partname = $file->isOld() ? $file->getArchiveName() : $file->getName();
+			$this->binaries[ $partname ] = $file->getPath();
+		}
 		return "    <upload>\n" .
 			$this->writeTimestamp( $file->getTimestamp() ) .
 			$this->writeContributor( $file->getUser( 'id' ), $file->getUser( 'text' ) ) .
-			"      " . Xml::elementClean( 'comment', null, $file->getDescription() ) . "\n" .
-			"      " . Xml::element( 'filename', null, $file->getName() ) . "\n" .
-			"      " . Xml::element( 'src', null, $file->getFullUrl() ) . "\n" .
-			"      " . Xml::element( 'size', null, $file->getSize() ) . "\n" .
+			"      " . Xml::ElementClean( 'comment', null, $file->getDescription() ) . "\n" .
+			"      " . Xml::Element( 'filename', null, $file->getName() ) . "\n" .
+			"      " . Xml::Element( 'src',
+			                      array('sha1' => $file->getSha1()),
+			                      $this->multipart ? "multipart://$partname" : $file->getFullUrl() ) . "\n" .
+			"      " . Xml::Element( 'size', null, $file->getSize() ) . "\n" .
 			"    </upload>\n";
 	}
 
@@ -653,6 +716,10 @@
 		$this->write( $string );
 	}
 
+	function writePart( $string ) {
+		$this->write( $string );
+	}
+
 	/**
 	 * Override to write to a different stream type.
 	 * @return bool
Index: includes/specials/SpecialImport.php
===================================================================
--- includes/specials/SpecialImport.php	(revision 82604)
+++ includes/specials/SpecialImport.php	(working copy)
@@ -3,6 +3,7 @@
  * Implements Special:Import
  *
  * Copyright © 2003,2005 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  * http://www.mediawiki.org/
  *
  * This program is free software; you can redistribute it and/or modify
@@ -325,12 +326,56 @@
 		$localCount = $wgLang->formatNum( $successCount );
 		$contentCount = $wgContLang->formatNum( $successCount );
 
+		/* No revisions in import */
+		if (!$pageInfo['lastExistingRevision'] && $successCount == 0)
+			$msg = wfMsgHtml('import-norevisions');
+
+		/* New page imported */
+		else if (!$pageInfo['lastLocalRevision'] && $successCount > 0)
+			$msg = wfMsgExt('import-revision-count-newpage', array('parsemag', 'escape'), $localCount);
+
+		else
+		{
+			$newer = !$pageInfo['lastExistingRevision'] ||
+				$pageInfo['lastLocalRevision']->getTimestamp() > $pageInfo['lastExistingRevision']->getTimestamp();
+			if ($successCount > 0)
+			{
+				/* Conflict */
+				if ($newer)
+				{
+					$linktext = wfMsgExt( 'import-conflict-difflink',
+						array( 'parsemag', 'escape' ),
+						$pageInfo['lastRevision']->getId(),
+						$pageInfo['lastLocalRevision']->getId() );
+					$link = $skin->makeKnownLinkObj(
+						$title, $linktext,
+						'diff=' . $pageInfo['lastRevision']->getId() .
+						"&oldid=" . $pageInfo['lastLocalRevision']->getId() );
+					$msg = wfMsgExt( 'import-conflict',
+						array( 'parsemag' ),
+						$localCount,
+						$link );
+				}
+				/* Page history continued with new revisions */
+				else
+					$msg = wfMsgExt('import-revision-count', array('parsemag', 'escape'), $localCount);
+			}
+			else
+			{
+				/* Local revision is newer */
+				if ($newer)
+					$msg = wfMsgHtml('import-nonewrevisions-localnewer');
+				/* No changes nowhere */
+				else
+					$msg = wfMsgHtml('import-nonewrevisions');
+			}
+		}
+
+		$msg = $skin->makeKnownLinkObj( $title ) . ': ' . $msg;
+
+		$wgOut->addHtml( "<li>$msg</li>" );
+
 		if( $successCount > 0 ) {
-			$wgOut->addHTML( "<li>" . $skin->linkKnown( $title ) . " " .
-				wfMsgExt( 'import-revision-count', array( 'parsemag', 'escape' ), $localCount ) .
-				"</li>\n"
-			);
-
 			$log = new LogPage( 'import' );
 			if( $this->mIsUpload ) {
 				$detail = wfMsgExt( 'import-logentry-upload-detail', array( 'content', 'parsemag' ),
@@ -349,19 +394,9 @@
 				}
 				$log->addEntry( 'interwiki', $title, $detail );
 			}
-
-			$comment = $detail; // quick
-			$dbw = wfGetDB( DB_MASTER );
-			$latest = $title->getLatestRevID();
-			$nullRevision = Revision::newNullRevision( $dbw, $title->getArticleId(), $comment, true );
-			$nullRevision->insertOn( $dbw );
-			$article = new Article( $title );
-			# Update page record
-			$article->updateRevisionOn( $dbw, $nullRevision );
-			wfRunHooks( 'NewRevisionFromEditComplete', array($article, $nullRevision, $latest, $wgUser) );
-		} else {
-			$wgOut->addHTML( "<li>" . $skin->linkKnown( $title ) . " " .
-				wfMsgHtml( 'import-nonewrevisions' ) . "</li>\n" );
+			// [MediaWiki4Intranet] do not insert any empty revisions because it leads
+			// to fancy bugs (infinitely multiplicated revisions) in the case of cross
+			// (2-way) import-export.
 		}
 	}
 
Index: includes/specials/SpecialExport.php
===================================================================
--- includes/specials/SpecialExport.php	(revision 82604)
+++ includes/specials/SpecialExport.php	(working copy)
@@ -3,6 +3,7 @@
  * Implements Special:Export
  *
  * Copyright © 2003-2008 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -28,9 +29,10 @@
  *
  * @ingroup SpecialPage
  */
+
 class SpecialExport extends SpecialPage {
 
-	private $curonly, $doExport, $pageLinkDepth, $templates;
+	private $curonly, $doExport, $linkDepth, $templates;
 	private $images;
 
 	public function __construct() {
@@ -50,44 +52,17 @@
 		$this->doExport = false;
 		$this->templates = $wgRequest->getCheck( 'templates' );
 		$this->images = $wgRequest->getCheck( 'images' ); // Doesn't do anything yet
-		$this->pageLinkDepth = $this->validateLinkDepth(
-			$wgRequest->getIntOrNull( 'pagelink-depth' )
-		);
+		$this->linkDepth = $this->validateLinkDepth(
+			$wgRequest->getIntOrNull( 'link-depth' ) );
 		$nsindex = '';
 
-		if ( $wgRequest->getCheck( 'addcat' ) ) {
-			$page = $wgRequest->getText( 'pages' );
-			$catname = $wgRequest->getText( 'catname' );
-
-			if ( $catname !== '' && $catname !== null && $catname !== false ) {
-				$t = Title::makeTitleSafe( NS_MAIN, $catname );
-				if ( $t ) {
-					/**
-					 * @todo Fixme: this can lead to hitting memory limit for very large
-					 * categories. Ideally we would do the lookup synchronously
-					 * during the export in a single query.
-					 */
-					$catpages = $this->getPagesFromCategory( $t );
-					if ( $catpages ) {
-						$page .= "\n" . implode( "\n", $catpages );
-					}
-				}
-			}
+		$state = $wgRequest->getValues();
+		$state['errors'] = array();
+		if ($state['addcat'])
+		{
+			self::addPagesExec($state);
+			$page = $state['pages'];
 		}
-		else if( $wgRequest->getCheck( 'addns' ) && $wgExportFromNamespaces ) {
-			$page = $wgRequest->getText( 'pages' );
-			$nsindex = $wgRequest->getText( 'nsindex', '' );
-
-			if ( strval( $nsindex ) !== ''  ) {
-				/**
-				 * Same implementation as above, so same @todo
-				 */
-				$nspages = $this->getPagesFromNamespace( $nsindex );
-				if ( $nspages ) {
-					$page .= "\n" . implode( "\n", $nspages );
-				}
-			}
-		}
 		else if( $wgRequest->wasPosted() && $par == '' ) {
 			$page = $wgRequest->getText( 'pages' );
 			$this->curonly = $wgRequest->getCheck( 'curonly' );
@@ -107,7 +82,7 @@
 				'limit' => $wgExportMaxHistory,
 			);
 			$historyCheck = $wgRequest->getCheck( 'history' );
-			
+
 			if ( $this->curonly ) {
 				$history = WikiExporter::CURRENT;
 			} elseif ( !$historyCheck ) {
@@ -129,7 +104,7 @@
 			// Default to current-only for GET requests.
 			$page = $wgRequest->getText( 'pages', $par );
 			$historyCheck = $wgRequest->getCheck( 'history' );
-			
+
 			if( $historyCheck ) {
 				$history = WikiExporter::FULL;
 			} else {
@@ -153,20 +128,20 @@
 
 		if ( $this->doExport ) {
 			$wgOut->disable();
-			
+
 			// Cancel output buffering and gzipping if set
 			// This should provide safer streaming for pages with history
 			wfResetOutputBuffers();
 			$wgRequest->response()->header( "Content-type: application/xml; charset=utf-8" );
-			
+
 			if( $wgRequest->getCheck( 'wpDownload' ) ) {
 				// Provide a sane filename suggestion
 				$filename = urlencode( $wgSitename . '-' . wfTimestampNow() . '.xml' );
 				$wgRequest->response()->header( "Content-disposition: attachment;filename={$filename}" );
 			}
-			
+
 			$this->doExport( $page, $history, $list_authors );
-			
+
 			return;
 		}
 
@@ -174,40 +149,39 @@
 
 		$form = Xml::openElement( 'form', array( 'method' => 'post',
 			'action' => $this->getTitle()->getLocalUrl( 'action=submit' ) ) );
-		$form .= Xml::inputLabel( wfMsg( 'export-addcattext' )    , 'catname', 'catname', 40 ) . '&#160;';
-		$form .= Xml::submitButton( wfMsg( 'export-addcat' ), array( 'name' => 'addcat' ) ) . '<br />';
 
-		if ( $wgExportFromNamespaces ) {
-			$form .= Xml::namespaceSelector( $nsindex, null, 'nsindex', wfMsg( 'export-addnstext' ) ) . '&#160;';
-			$form .= Xml::submitButton( wfMsg( 'export-addns' ), array( 'name' => 'addns' ) ) . '<br />';
-		}
+		foreach ($state['errors'] as $e)
+			$form .= wfMsgExt($e[0], array('parse'), $e[1]);
 
+		$form .= self::addPagesForm($state);
+
 		$form .= Xml::element( 'textarea', array( 'name' => 'pages', 'cols' => 40, 'rows' => 10 ), $page, false );
 		$form .= '<br />';
 
 		if( $wgExportAllowHistory ) {
-			$form .= Xml::checkLabel( wfMsg( 'exportcuronly' ), 'curonly', 'curonly', true ) . '<br />';
+			$form .= Xml::checkLabel( wfMsg( 'exportcuronly' ), 'curonly', 'curonly', $wgRequest->getCheck('curonly') ? true : false ) . '<br />';
 		} else {
 			$wgOut->addHTML( wfMsgExt( 'exportnohistory', 'parse' ) );
 		}
-		
-		$form .= Xml::checkLabel( wfMsg( 'export-templates' ), 'templates', 'wpExportTemplates', false ) . '<br />';
-		
-		if( $wgExportMaxLinkDepth || $this->userCanOverrideExportDepth() ) {
-			$form .= Xml::inputLabel( wfMsg( 'export-pagelinks' ), 'pagelink-depth', 'pagelink-depth', 20, 0 ) . '<br />';
-		}
+		$form .= Xml::checkLabel( wfMsg( 'export-templates' ), 'templates', 'wpExportTemplates', $wgRequest->getCheck('templates') ? true : false ) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-pagelinks' ), 'pagelinks', 'wpExportPagelinks', $wgRequest->getCheck('pagelinks') ? true : false ) . '<br />';
 		// Enable this when we can do something useful exporting/importing image information. :)
-		//$form .= Xml::checkLabel( wfMsg( 'export-images' ), 'images', 'wpExportImages', false ) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-images' ), 'images', 'wpExportImages', $wgRequest->getCheck('images') ? true : false ) . '<br />';
 		$form .= Xml::checkLabel( wfMsg( 'export-download' ), 'wpDownload', 'wpDownload', true ) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-selfcontained' ), 'selfcontained', 'wpSelfContained', $wgRequest->getCheck('selfcontained') ? true : false ) . '<br />';
+		if( $wgExportMaxLinkDepth || $this->userCanOverrideExportDepth() ) {
+			$form .= Xml::inputLabel( wfMsg( 'export-link-depth' ), 'link-depth', 'link-depth', 20, $wgRequest->getVal('link-depth') ) . '<br />';
+		}
 
 		$form .= Xml::submitButton( wfMsg( 'export-submit' ), $wgUser->getSkin()->tooltipAndAccessKeyAttribs( 'export' ) );
 		$form .= Xml::closeElement( 'form' );
-		
+
 		$wgOut->addHTML( $form );
 	}
 
 	private function userCanOverrideExportDepth() {
 		global $wgUser;
+
 		return $wgUser->isAllowed( 'override-export-depth' );
 	}
 
@@ -220,6 +194,9 @@
 	 *                      not returning full history)
 	 */
 	private function doExport( $page, $history, $list_authors ) {
+		global $wgRequest;
+
+		$inputPages = array(); // Set of original pages to pass on to further manipulation...
 		$pageSet = array(); // Inverted index of all pages to look up
 
 		// Split up and normalize input
@@ -228,38 +205,33 @@
 			$title = Title::newFromText( $pageName );
 			if( $title && $title->getInterwiki() == '' && $title->getText() !== '' ) {
 				// Only record each page once!
+				$inputPages[] = $title;
 				$pageSet[$title->getPrefixedText()] = true;
 			}
 		}
 
-		// Set of original pages to pass on to further manipulation...
-		$inputPages = array_keys( $pageSet );
-
 		// Look up any linked pages if asked...
-		if( $this->templates ) {
-			$pageSet = $this->getTemplates( $inputPages, $pageSet );
-		}
-		$linkDepth = $this->pageLinkDepth;
-		if( $linkDepth ) {
-			$pageSet = $this->getPageLinks( $inputPages, $pageSet, $linkDepth );
-		}
+		$t = $wgRequest->getCheck( 'templates' ) ? 1 : 0;
+		$p = $wgRequest->getCheck( 'pagelinks' ) ? 1 : 0;
+		$i = $wgRequest->getCheck( 'images' ) ? 1 : 0;
+		$step = 0;
+		do
+		{
+			$added = 0;
+			if( $t ) $added += self::getTemplates( $inputPages, $pageSet );
+			if( $p ) $added += self::getPagelinks( $inputPages, $pageSet );
+			if( $i ) $added += self::getImages( $inputPages, $pageSet );
+			$step++;
+		} while( $t+$p+$i > 1 && $added > 0 && ( !$this->linkDepth || $step < $this->linkDepth ) );
 
-		/*
-		 // Enable this when we can do something useful exporting/importing image information. :)
-		 if( $this->images ) ) {
-		 $pageSet = $this->getImages( $inputPages, $pageSet );
-		 }
-		 */
+/*op-patch|TS|2010-04-26|HaloACL|SafeTitle|start*/
+		$pages = array();
+		/* Bug 8824: Only export pages the user can read */
+		foreach ( $inputPages as $title )
+			if ( $title->userCanRead() && ( !method_exists( $title, 'userCanReadEx' ) || $title->userCanReadEx() ) )
+				$pages[] = $title;
+/*op-patch|TS|2010-04-26|end*/
 
-		$pages = array_keys( $pageSet );
-
-		// Normalize titles to the same format and remove dupes, see bug 17374
-		foreach( $pages as $k => $v ) {
-			$pages[$k] = str_replace( " ", "_", $v );
-		}
-		
-		$pages = array_unique( $pages );
-
 		/* Ok, let's get to it... */
 		if( $history == WikiExporter::CURRENT ) {
 			$lb = false;
@@ -279,30 +251,11 @@
 		
 		$exporter = new WikiExporter( $db, $history, $buffer );
 		$exporter->list_authors = $list_authors;
+		$exporter->dumpUploads = $wgRequest->getCheck('images') ? true : false;
+		$exporter->selfContained = $wgRequest->getCheck('selfcontained') ? true : false;
 		$exporter->openStream();
 		
-		foreach( $pages as $page ) {
-			/*
-			 if( $wgExportMaxHistory && !$this->curonly ) {
-			 $title = Title::newFromText( $page );
-			 if( $title ) {
-			 $count = Revision::countByTitle( $db, $title );
-			 if( $count > $wgExportMaxHistory ) {
-			 wfDebug( __FUNCTION__ .
-			 ": Skipped $page, $count revisions too big\n" );
-			 continue;
-			 }
-			 }
-			 }*/
-			#Bug 8824: Only export pages the user can read
-			$title = Title::newFromText( $page );
-			if( is_null( $title ) ) {
-				continue; #TODO: perhaps output an <error> tag or something.
-			}
-			if( !$title->userCanRead() ) {
-				continue; #TODO: perhaps output an <error> tag or something.
-			}
-
+		foreach( $pages as $title ) {
 			$exporter->pageByTitle( $title );
 		}
 
@@ -313,58 +266,97 @@
 		}
 	}
 
-	private function getPagesFromCategory( $title ) {
-		global $wgContLang;
+	static function addPagesExec(&$state)
+	{
+		$catname = $state['catname'];
+		$modifydate = $state['modifydate'];
+		$namespace = $state['namespace'];
+		$closure = $state['closure'];
+		$catpages = self::getPagesFromCategory($catname, $modifydate, $namespace, $closure);
+		if ($catpages)
+		{
+			foreach ($catpages as $title)
+			{
+/*op-patch|TS|2010-04-26|HaloACL|SafeTitle|start*/
+				if (!method_exists($title, 'userCanReadEx') || $title->userCanReadEx())
+/*op-patch|TS|2010-04-26|end*/
+					$state['pages'] .= "\n" . $title->getPrefixedText();
+			}
+		}
+		$state['errors'] = array();
+		if (!$catname && strlen($state['catname']))
+			$state['errors'][] = array('export-invalid-catname', $state['catname']);
+		if ($modifydate)
+			$state['modifydate'] = wfTimestamp(TS_DB, $modifydate);
+		else if ($state['modifydate'])
+			$state['errors'][] = array('export-invalid-modifydate', $state['modifydate']);
+		if (!$namespace && strlen($state['namespace']))
+			$state['errors'][] = array('export-invalid-namespace', $state['namespace']);
+	}
 
-		$name = $title->getDBkey();
+	static function addPagesForm($state)
+	{
+		$form .= '<fieldset class="addpages">';
+		$form .= '<legend>' . wfMsgExt('export-addpages', 'parse') . '</legend>';
+		$form .= '<div class="ap_catname">' . Xml::inputLabel(wfMsg('export-catname'), 'catname', 'catname', 40, $state['catname']) .
+		         '<br />' . Xml::checkLabel(wfMsg('export-closure'), 'closure', 'wpExportClosure', $state['closure'] ? true : false) . '</div>';
+		$form .= '<div class="ap_namespace">' . Xml::inputLabel(wfMsg('export-namespace'), 'namespace', 'namespace', 20, $state['namespace']) . '</div>';
+		$form .= '<div class="ap_modifydate">' . Xml::inputLabel(wfMsg('export-modifydate'), 'modifydate', 'modifydate', 20, $state['modifydate']) . '</div>';
+		$form .= '<div class="ap_submit">' . Xml::submitButton(wfMsg('export-addcat'), array('name' => 'addcat')) . '</div>';
+		$form .= '</fieldset>';
+		return $form;
+	}
 
-		$dbr = wfGetDB( DB_SLAVE );
-		$res = $dbr->select(
-			array( 'page', 'categorylinks' ),
-			array( 'page_namespace', 'page_title' ),
-			array( 'cl_from=page_id', 'cl_to' => $name ),
-			__METHOD__,
-			array( 'LIMIT' => '5000' )
-		);
-
+	static function getPagesFromCategory(&$catname, &$modifydate, &$namespace, $closure)
+	{
+		if (!strlen($catname) || !($catname = Title::makeTitleSafe(NS_CATEGORY, $catname)))
+			$catname = NULL;
+		else
+			$catname = $catname->getDbKey();
+		if (!strlen($modifydate) || !($modifydate = wfTimestampOrNull(TS_MW, $modifydate)))
+			$modifydate = NULL;
+		if (!strlen($namespace) || !($namespace = Title::newFromText("$namespace:A", NS_MAIN)))
+			$namespace = NULL;
+		else
+			$namespace = $namespace->getNamespace();
 		$pages = array();
-		
-		foreach ( $res as $row ) {
-			$n = $row->page_title;
-			if ($row->page_namespace) {
-				$ns = $wgContLang->getNsText( $row->page_namespace );
-				$n = $ns . ':' . $n;
-			}
-
-			$pages[] = $n;
-		}
-		return $pages;
+		self::rgetPagesFromCategory($catname, $modifydate, $namespace, $closure, $pages);
+		return array_values($pages);
 	}
 
-	private function getPagesFromNamespace( $nsindex ) {
+	static function rgetPagesFromCategory($catname, $modifydate, $namespace, $closure, &$pages)
+	{
 		global $wgContLang;
 
-		$dbr = wfGetDB( DB_SLAVE );
-		$res = $dbr->select(
-			'page',
-			array( 'page_namespace', 'page_title' ),
-			array( 'page_namespace' => $nsindex ),
-			__METHOD__,
-			array( 'LIMIT' => '5000' )
-		);
+		$dbr = wfGetDB(DB_SLAVE);
+		$from = array('page');
+		$where = array();
 
-		$pages = array();
-		
-		foreach ( $res as $row ) {
-			$n = $row->page_title;
-			
-			if ( $row->page_namespace ) {
-				$ns = $wgContLang->getNsText( $row->page_namespace );
-				$n = $ns . ':' . $n;
-			}
+		if (!is_null($catname))
+		{
+			$from[] = 'categorylinks';
+			$where[] = 'cl_from=page_id';
+			$where['cl_to'] = $catname;
+		}
 
-			$pages[] = $n;
+		if (!is_null($modifydate))
+			$where[] = "page_touched>$modifydate";
+
+		if (!is_null($namespace))
+			$where['page_namespace'] = $namespace;
+
+		$res = $dbr->select( $from, array( 'page_namespace', 'page_title' ), $where, __METHOD__ );
+		while ( $row = $dbr->fetchRow( $res ) )
+		{
+			$row = Title::makeTitleSafe( $row['page_namespace'], $row['page_title'] );
+			if ($row && !$pages[ $row->getArticleId() ] )
+			{
+				$pages[ $row->getArticleId() ] = $row;
+				if ( $closure && $row->getNamespace() == NS_CATEGORY )
+					self::rgetPagesFromCategory( $row->getDbKey(), $modifydate, $namespace, $closure, $pages );
+			}
 		}
+
 		return $pages;
 	}
 
@@ -374,8 +366,10 @@
 	 * @param $pageSet array, associative array indexed by titles for output
 	 * @return array associative array index by titles
 	 */
-	private function getTemplates( $inputPages, $pageSet ) {
-		return $this->getLinks( $inputPages, $pageSet,
+	private function getTemplates( &$inputPages, &$pageSet ) {
+		return $this->getLinks(
+			$inputPages,
+			$pageSet,
 			'templatelinks',
 			array( 'tl_namespace AS namespace', 'tl_title AS title' ),
 			array( 'page_id=tl_from' )
@@ -388,9 +382,8 @@
 	private function validateLinkDepth( $depth ) {
 		global $wgExportMaxLinkDepth;
 		
-		if( $depth < 0 ) {
+		if( $depth <= 0 )
 			return 0;
-		}
 		
 		if ( !$this->userCanOverrideExportDepth() ) {
 			if( $depth > $wgExportMaxLinkDepth ) {
@@ -398,26 +391,18 @@
 			}
 		}
 		
-		/*
-		 * There's a HARD CODED limit of 5 levels of recursion here to prevent a
-		 * crazy-big export from being done by someone setting the depth
-		 * number too high. In other words, last resort safety net.
-		 */
-		return intval( min( $depth, 5 ) );
+		return $depth;
 	}
 
 	/** Expand a list of pages to include pages linked to from that page. */
-	private function getPageLinks( $inputPages, $pageSet, $depth ) {
-		for( ; $depth > 0; --$depth ) {
-			$pageSet = $this->getLinks(
-				$inputPages, $pageSet, 'pagelinks',
-			  	array( 'pl_namespace AS namespace', 'pl_title AS title' ),
-				array( 'page_id=pl_from' )
-			);
-			$inputPages = array_keys( $pageSet );
-		}
-		
-		return $pageSet;
+	private function getPageLinks( &$inputPages, &$pageSet ) {
+		return $this->getLinks(
+			$inputPages,
+			$pageSet,
+			'pagelinks',
+			array( 'pl_namespace AS namespace', 'pl_title AS title' ),
+			array( 'page_id=pl_from' )
+		);
 	}
 
 	/**
@@ -428,7 +413,7 @@
 	 * 
 	 * @return array associative array index by titles
 	 */
-	private function getImages( $inputPages, $pageSet ) {
+	private function getImages( &$inputPages, &$pageSet ) {
 		return $this->getLinks(
 			$inputPages,
 			$pageSet,
@@ -440,38 +425,34 @@
 
 	/**
 	 * Expand a list of pages to include items used in those pages.
+	 * @private
 	 */
-	private function getLinks( $inputPages, $pageSet, $table, $fields, $join ) {
+	private function getLinks( &$inputPages, &$pageSet, $table, $fields, $join ) {
 		$dbr = wfGetDB( DB_SLAVE );
-		
-		foreach( $inputPages as $page ) {
-			$title = Title::newFromText( $page );
-			
-			if( $title ) {
-				$pageSet[$title->getPrefixedText()] = true;
-				/// @todo Fixme: May or may not be more efficient to batch these
-				///        by namespace when given multiple input pages.
-				$result = $dbr->select(
-					array( 'page', $table ),
-					$fields,
-					array_merge(
-						$join,
-						array(
-							'page_namespace' => $title->getNamespace(),
-							'page_title' => $title->getDBkey()
-						)
-					),
-					__METHOD__
-				);
-				
-				foreach( $result as $row ) {
-					$template = Title::makeTitle( $row->namespace, $row->title );
-					$pageSet[$template->getPrefixedText()] = true;
+		$byns = array();
+		foreach( $inputPages as $title )
+			$byns[$title->getNamespace()][] = $title->getDBkey();
+		$added = 0;
+		foreach( $byns as $ns => $titles )
+		{
+			$result = $dbr->select(
+				array( 'page', $table ),
+				$fields,
+				array_merge( $join, array(
+					'page_namespace' => $ns,
+					'page_title' => $titles ) ),
+				__METHOD__ );
+			foreach( $result as $row )
+			{
+				$add = Title::makeTitle( $row->namespace, $row->title );
+				if( $add && !$pageSet[ $add->getPrefixedText() ] )
+				{
+					$pageSet[ $add->getPrefixedText() ] = true;
+					$inputPages[] = $add;
+					$added++;
 				}
 			}
 		}
-		
-		return $pageSet;
+		return $added;
 	}
-	
-}
\ No newline at end of file
+}
Index: includes/Import.php
===================================================================
--- includes/Import.php	(revision 82604)
+++ includes/Import.php	(working copy)
@@ -3,6 +3,7 @@
  * MediaWiki page data importer
  *
  * Copyright © 2003,2005 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  * http://www.mediawiki.org/
  *
  * This program is free software; you can redistribute it and/or modify
@@ -32,6 +33,7 @@
  */
 class WikiImporter {
 	private $reader = null;
+	private $importSource;
 	private $mLogItemCallback, $mUploadCallback, $mRevisionCallback, $mPageCallback;
 	private $mSiteInfoCallback, $mTargetNamespace, $mPageOutCallback;
 	private $mDebug;
@@ -43,6 +45,7 @@
 		$this->reader = new XMLReader();
 
 		stream_wrapper_register( 'uploadsource', 'UploadSourceAdapter' );
+		$this->importSource = $source;
 		$id = UploadSourceAdapter::registerSource( $source );
 		$this->reader->open( "uploadsource://$id" );
 
@@ -189,12 +192,13 @@
 	}
 
 	/**
-	 * Dummy for now...
+	 * Per-revision file import callback, performs the upload.
+	 * @param $revision WikiRevision
+	 * @private
 	 */
 	public function importUpload( $revision ) {
-		//$dbw = wfGetDB( DB_MASTER );
-		//return $dbw->deadlockLoop( array( $revision, 'importUpload' ) );
-		return false;
+		$dbw = wfGetDB( DB_MASTER );
+		return $dbw->deadlockLoop( array( $revision, 'importUpload' ) );
 	}
 
 	/**
@@ -248,6 +252,16 @@
 	}
 
 	/**
+	 * Notify the callback function when a </upload> is closed.
+	 */
+	private function uploadCallback( $revision ) {
+		if( isset( $this->mUploadCallback ) ) {
+			$args = func_get_args();
+			call_user_func_array( $this->mUploadCallback, $args );
+		}
+	}
+
+	/**
 	 * Notify the callback function of a revision
 	 * @param $revision A WikiRevision object
 	 */
@@ -453,10 +467,36 @@
 		return $this->logItemCallback( $revision );
 	}
 
+	static function getLastLocalRevision( $title )
+	{
+		/* We need to skip import-info Null Revisions.
+		   They have rev_text_id equal to previous revision. */
+		$dbr = wfGetDB( DB_MASTER );
+		$res = $dbr->select( 'revision', 'rev_id, rev_text_id',
+			array( 'rev_page' => $title->getArticleId(), 'rev_len IS NOT NULL' ),
+			__METHOD__,
+			array( 'ORDER BY' => 'rev_timestamp DESC' ) );
+		$row = $res->fetchRow();
+		$rev_id = $row['rev_id'];
+		$text_id = $row['rev_text_id'];
+		while (($row = $res->fetchRow()) && $text_id == $row['rev_text_id'])
+			$rev_id = $row['rev_id'];
+		$res->free();
+		if ($rev_id)
+			return Revision::newFromId( $rev_id );
+		return NULL;
+	}
+
 	private function handlePage() {
 		// Handle page data.
 		$this->debug( "Enter page handler." );
-		$pageInfo = array( 'revisionCount' => 0, 'successfulRevisionCount' => 0 );
+		$pageInfo = array(
+			'revisionCount' => 0,
+			'successfulRevisionCount' => 0,
+			'lastRevision' => NULL,
+			'lastLocalRevision' => NULL,
+			'lastExistingRevision' => NULL,
+		);
 
 		// Fields that can just be stuffed in the pageInfo object
 		$normalFields = array( 'title', 'id', 'redirect', 'restrictions' );
@@ -490,6 +530,7 @@
 
 					$this->pageCallback( $title );
 					list( $pageInfo['_title'], $origTitle ) = $title;
+					$pageInfo['lastLocalRevision'] = self::getLastLocalRevision( $pageInfo['_title'] );
 				}
 			} elseif ( $tag == 'revision' ) {
 				$this->handleRevision( $pageInfo );
@@ -537,8 +578,15 @@
 		}
 
 		$pageInfo['revisionCount']++;
-		if ( $this->processRevision( $pageInfo, $revisionInfo ) ) {
-			$pageInfo['successfulRevisionCount']++;
+		if ( $r = $this->processRevision( $pageInfo, $revisionInfo ) ) {
+			if ( is_object($r) && $r->_imported )
+			{
+				$pageInfo['successfulRevisionCount']++;
+				$pageInfo['lastRevision'] = $r;
+			}
+			elseif ( is_object($r) && ( !$pageInfo['lastExistingRevision'] ||
+				$r->getTimestamp() > $pageInfo['lastExistingRevision']->getTimestamp() ) )
+				$pageInfo['lastExistingRevision'] = $r;
 		}
 	}
 
@@ -589,6 +637,8 @@
 				// Do nothing
 			} elseif ( in_array( $tag, $normalFields ) ) {
 				$uploadInfo[$tag] = $this->nodeContents();
+				if ( $tag == 'src' && $this->workRevision && ( $sha1 = $this->reader->getAttribute('sha1') ) )
+					$uploadInfo['sha1'] = $sha1;
 			} elseif ( $tag == 'contributor' ) {
 				$uploadInfo['contributor'] = $this->handleContributor();
 			} elseif ( $tag != '#text' ) {
@@ -608,7 +658,14 @@
 		$revision->setTimestamp( $uploadInfo['timestamp'] );
 		$revision->setText( $uploadInfo['text'] );
 		$revision->setFilename( $uploadInfo['filename'] );
-		$revision->setSrc( $uploadInfo['src'] );
+		/* Pass temp file path for multipart parts */
+		if( substr( $uploadInfo['src'], 0, 12 ) == 'multipart://' )
+		{
+			if ( $p = $this->importSource->parts[ substr( $uploadInfo['src'], 12 ) ] )
+				$revision->setSrc( $p['tempfile'] );
+		}
+		else
+			$revision->setSrc( $uploadInfo['src'] );
 		$revision->setSize( intval( $uploadInfo['size'] ) );
 		$revision->setComment( $uploadInfo['comment'] );
 
@@ -789,6 +846,7 @@
 	var $type = "";
 	var $action = "";
 	var $params = "";
+	var $tempfile = NULL;
 
 	function setTitle( $title ) {
 		if( is_object( $title ) ) {
@@ -837,6 +895,10 @@
 		$this->filename = $filename;
 	}
 
+	function setSha1( $sha1 ) {
+		$this->sha1 = trim( $sha1 );
+	}
+
 	function setSize( $size ) {
 		$this->size = intval( $size );
 	}
@@ -889,6 +951,10 @@
 		return $this->filename;
 	}
 
+	function getSha1() {
+		return $this->sha1;
+	}
+
 	function getSize() {
 		return $this->size;
 	}
@@ -906,6 +972,14 @@
 	}
 
 	function importOldRevision() {
+		# Check edit permission
+		if( !$this->getTitle()->userCan('edit') )
+		{
+			global $wgUser;
+			wfDebug( __METHOD__ . ": edit permission denied for [[" . $this->title->getPrefixedText() . "]], user " . $wgUser->getName() );
+			return false;
+		}
+
 		$dbw = wfGetDB( DB_MASTER );
 
 		# Sneak a single revision into place
@@ -931,7 +1005,7 @@
 		} else {
 			$created = false;
 
-			$prior = $dbw->selectField( 'revision', '1',
+			$prior = $dbw->selectField( 'revision', 'rev_id',
 				array( 'rev_page' => $pageId,
 					'rev_timestamp' => $dbw->timestamp( $this->timestamp ),
 					'rev_user_text' => $userText,
@@ -939,10 +1013,11 @@
 				__METHOD__
 			);
 			if( $prior ) {
+				$prior = Revision::newFromId( $prior );
 				// FIXME: this could fail slightly for multiple matches :P
 				wfDebug( __METHOD__ . ": skipping existing revision for [[" .
 					$this->title->getPrefixedText() . "]], timestamp " . $this->timestamp . "\n" );
-				return false;
+				return $prior;
 			}
 		}
 
@@ -985,7 +1060,9 @@
 		}
 		$GLOBALS['wgTitle'] = $tempTitle;
 
-		return true;
+		# A hack. TOdo it better?
+		$revision->_imported = true;
+		return $revision;
 	}
 	
 	function importLogItem() {
@@ -996,6 +1073,13 @@
 				$this->timestamp . "\n" );
 			return;
 		}
+		# Check edit permission
+		if( !$this->getTitle()->userCan('edit') )
+		{
+			global $wgUser;
+			wfDebug( __METHOD__ . ": edit permission denied for [[" . $this->title->getPrefixedText() . "]], user " . $wgUser->getName() );
+			return false;
+		}
 		# Check if it exists already
 		// FIXME: use original log ID (better for backups)
 		$prior = $dbw->selectField( 'logging', '1',
@@ -1031,29 +1115,16 @@
 		$dbw->insert( 'logging', $data, __METHOD__ );
 	}
 
-	function importUpload() {
-		wfDebug( __METHOD__ . ": STUB\n" );
+	function importUpload()
+	{
+		# Check edit permission
+		if( !$this->getTitle()->userCan('edit') )
+		{
+			global $wgUser;
+			wfDebug( __METHOD__ . ": edit permission denied for [[" . $this->title->getPrefixedText() . "]], user " . $wgUser->getName() );
+			return false;
+		}
 
-		/**
-			// from file revert...
-			$source = $this->file->getArchiveVirtualUrl( $this->oldimage );
-			$comment = $wgRequest->getText( 'wpComment' );
-			// TODO: Preserve file properties from database instead of reloading from file
-			$status = $this->file->upload( $source, $comment, $comment );
-			if( $status->isGood() ) {
-		*/
-
-		/**
-			// from file upload...
-		$this->mLocalFile = wfLocalFile( $nt );
-		$this->mDestName = $this->mLocalFile->getName();
-		//....
-			$status = $this->mLocalFile->upload( $this->mTempPath, $this->mComment, $pageText,
-			File::DELETE_SOURCE, $this->mFileProps );
-			if ( !$status->isGood() ) {
-				$resultDetails = array( 'internal' => $status->getWikiText() );
-		*/
-
 		// @todo Fixme: upload() uses $wgUser, which is wrong here
 		// it may also create a page without our desire, also wrong potentially.
 		// and, it will record a *current* upload, but we might want an archive version here
@@ -1064,26 +1135,67 @@
 			return false;
 		}
 
+		/* First check if file already exists */
+		if ($file->exists())
+		{
+			/* Backward-compatibility: support export files without sha1 */
+			if ($this->getSha1() && $file->getSha1() == $this->getSha1() ||
+				!$this->getSha1() && $file->getTimestamp() == $this->getTimestamp())
+			{
+				wfDebug( "IMPORT: File already exists and is equal to imported (".$this->getTimestamp().").\n" );
+				return false;
+			}
+			$history = $file->getHistory(null, $this->getTimestamp(), $this->getTimestamp());
+			foreach ($history as $oldfile)
+			{
+				if (!$this->getSha1() || $oldfile->getSha1() == $this->getSha1())
+				{
+					wfDebug( "IMPORT: File revision already exists at its timestamp (".$this->getTimestamp().") and is equal to imported.\n" );
+					return false;
+				}
+			}
+		}
+
+		/* Get file source into a temporary file */
 		$source = $this->downloadSource();
 		if( !$source ) {
 			wfDebug( "IMPORT: Could not fetch remote file. :(\n" );
 			return false;
 		}
 
-		$status = $file->upload( $source,
-			$this->getComment(),
-			$this->getComment(), // Initial page, if none present...
-			File::DELETE_SOURCE,
-			false, // props...
-			$this->getTimestamp() );
+		// @fixme upload() uses $wgUser, which is wrong here
+		// it may also create a page without our desire, also wrong potentially.
 
+		if ($file->exists() && $file->getTimestamp() > $this->getTimestamp())
+		{
+			/* Upload an *archive* version */
+			wfDebug( "Importing an archive $arch version of file (".$this->getTimestamp().")\n" );
+			$status = $file->uploadIntoArchive( $source,
+				$this->getComment(),
+				$this->getComment(), // Initial page, if none present...
+				File::DELETE_SOURCE,
+				false, // props...
+				$this->getTimestamp() );
+		}
+		else
+		{
+			wfDebug( "Importing a new current version of file (".$this->getTimestamp().")\n" );
+			/* Upload a *current* version */
+			$status = $file->upload( $source,
+				$this->getComment(),
+				$this->getComment(), // Initial page, if none present...
+				File::DELETE_SOURCE,
+				false, // props...
+				$this->getTimestamp() );
+		}
+
 		if( $status->isGood() ) {
 			// yay?
-			wfDebug( "IMPORT: is ok?\n" );
+			wfDebug( "IMPORT: file imported OK\n" );
 			return true;
 		}
 
-		wfDebug( "IMPORT: is bad? " . $status->getXml() . "\n" );
+		wfDebug( "IMPORT: file import FAILED: " . $status->getXml() . "\n" );
 		return false;
 
 	}
@@ -1094,29 +1206,41 @@
 			return false;
 		}
 
-		$tempo = tempnam( wfTempDir(), 'download' );
-		$f = fopen( $tempo, 'wb' );
+		$src = $this->getSrc();
+		if ( !$src )
+			return false;
+		/* If the file is attached as a part of multipart document, return temp file name */
+		if ( is_file( $src ) )
+			return $src;
+
+		/* If the file is attached as a URL, download it */
+		$this->tempfile = tempnam( wfTempDir(), 'download' );
+		$f = fopen( $this->tempfile, 'wb' );
 		if( !$f ) {
-			wfDebug( "IMPORT: couldn't write to temp file $tempo\n" );
+			wfDebug( "IMPORT: couldn't write to temp file ".$this->tempfile."\n" );
 			return false;
 		}
 
-		// @todo Fixme!
-		$src = $this->getSrc();
+		// @fixme!
 		$data = Http::get( $src );
 		if( !$data ) {
 			wfDebug( "IMPORT: couldn't fetch source $src\n" );
 			fclose( $f );
-			unlink( $tempo );
+			unlink( $this->tempfile );
 			return false;
 		}
 
 		fwrite( $f, $data );
 		fclose( $f );
 
-		return $tempo;
+		return $this->tempfile;
 	}
 
+	function __destruct()
+	{
+		if ( $this->tempfile && is_file( $this->tempfile ) )
+			unlink( $this->tempfile );
+	}
 }
 
 /**
@@ -1141,6 +1265,10 @@
 			return $this->mString;
 		}
 	}
+
+	function nextPart() {
+		return false;
+	}
 }
 
 /**
@@ -1148,20 +1276,131 @@
  * @ingroup SpecialPage
  */
 class ImportStreamSource {
-	function __construct( $handle ) {
+
+	var $buf;
+	var $eop;
+	var $boundary;
+
+	const BUF_SIZE = 65536;
+
+	function __construct( $handle )
+	{
 		$this->mHandle = $handle;
+		$this->eop = false;
+		$this->buf = '';
+		$this->boundary = '';
+		$pos = ftell($this->mHandle);
+		$s = fgets($this->mHandle);
+		/* multipart-related? */
+		if (preg_match("/Content-Type:\s*multipart\/related; boundary=([^\r\n]+)\r*\n/s", $s, $m))
+		{
+			$this->boundary = $m[1];
+			$this->parts = array();
+			/* Unpack multipart document to individual parts.
+			 * The import function must see already downloaded parts.
+			 * But they are dumped AFTER XML part inside the multipart document.
+			 * To be more exact, their position is simply undefined.
+			 */
+			while (!feof($this->mHandle))
+			{
+				$s = trim(fgets($this->mHandle));
+				if ($s != $this->boundary)
+					break;
+				$part = array();
+				/* Read part headers */
+				while ($s != "\n" && $s != "\r\n")
+				{
+					$s = fgets($this->mHandle);
+					if (preg_match('/([a-z0-9\-\_]+):\s*(.*?)\s*$/is', $s, $m))
+						$part[str_replace('-','_',strtolower($m[1]))] = $m[2];
+				}
+				/* Read part data */
+				$tempfile = tempnam(wfTempDir(), "imp");
+				$tempfp = fopen($tempfile, "wb");
+				if (is_numeric($part['content_length']))
+				{
+					$done = 0;
+					$buf = true;
+					while ($done < $part['content_length'] && $buf)
+					{
+						$buf = fread($this->mHandle, min(self::BUF_SIZE, $part['content_length'] - $done));
+						if ($tempfp)
+							fwrite($tempfp, $buf);
+						$done += strlen($buf);
+					}
+				}
+				else
+				{
+					$buf = true;
+					while ($buf)
+					{
+						$buf = fread($this->mHandle, self::BUF_SIZE);
+						if (($p = strpos($buf, "\n".$this->boundary)) !== false)
+						{
+							$pp = ftell($this->mHandle);
+							fseek($this->mHandle, $p+1-strlen($buf), 1);
+							fwrite($tempfp, substr($buf, 0, $p+1));
+							break;
+						}
+						else
+						{
+							/* For the case when $this->boundary crosses the boundary of read buffer */
+							if (strlen($buf) == self::BUF_SIZE &&
+								($p = strrpos($buf, "\n")) !== false)
+							{
+								fseek($this->mHandle, $p+1-self::BUF_SIZE, 1);
+								$buf = substr($buf, 0, $p+1);
+							}
+							fwrite($tempfp, $buf);
+						}
+					}
+				}
+				fclose($tempfp);
+				/* Remember temp file name */
+				$part['tempfile'] = $tempfile;
+				if ($part['content_id'])
+				{
+					$part['sha1'] = sha1_file($part['tempfile']);
+					$this->parts[$part['content_id']] = $part;
+				}
+				else
+					unlink($tempfile);
+			}
+			/* Open XML part for reading */
+			if ($this->parts['Revisions'])
+			{
+				fclose($this->mHandle);
+				$this->mHandle = fopen($this->parts['Revisions']['tempfile'], 'rb');
+			}
+		}
+		/* Else: simply an XML file (not a multipart/related) */
+		else
+			fseek($this->mHandle, $pos, 0);
 	}
 
+	/* Destructor, removes temporary files. */
+	function __destruct()
+	{
+		wfSuppressWarnings();
+		if ($this->mHandle)
+			fclose ($this->mHandle);
+		if ($this->parts)
+			foreach ($this->parts as $part)
+				unlink ($part['tempfile']);
+		wfRestoreWarnings();
+	}
+
 	function atEnd() {
 		return feof( $this->mHandle );
 	}
 
+	/* read next XML part chunk */
 	function readChunk() {
-		return fread( $this->mHandle, 32768 );
+		return fread( $this->mHandle, self::BUF_SIZE );
 	}
 
 	static function newFromFile( $filename ) {
-		$file = @fopen( $filename, 'rt' );
+		$file = @fopen( $filename, 'rb' );
 		if( !$file ) {
 			return Status::newFatal( "importcantopen" );
 		}
Index: languages/messages/MessagesRu.php
===================================================================
--- languages/messages/MessagesRu.php	(revision 82604)
+++ languages/messages/MessagesRu.php	(working copy)
@@ -2696,13 +2696,21 @@
 'exportnohistory'   => "----
 '''Замечание:''' экспорт полной истории изменений страниц отключён из-за проблем с производительностью.",
 'export-submit'     => 'Экспортировать',
-'export-addcattext' => 'Добавить страницы из категории:',
+'export-addpages'   => "'''Добавить страницы:'''",
 'export-addcat'     => 'Добавить',
-'export-addnstext'  => 'Добавить страницы из пространства имён:',
-'export-addns'      => 'Добавить',
+'export-catname'    => 'Категория:',
+'export-modifydate' => 'Изменённые после:',
+'export-namespace'  => 'Пространство имён:',
+'export-invalid-catname' => '<font color=red>\'\'\'Некорректное имя категории проигнорировано: \'$1\'\'\'\'.</font>',
+'export-invalid-namespace' => '<font color=red>\'\'\'Неизвестное пространство имён проигнорировано: \'$1\'\'\'\'.</font>',
+'export-invalid-modifydate' => '<font color=red>\'\'\'Некорректные дата и время проигнорированы (используйте формат <u>YYYY-MM-DD HH:MM:SS</u>): \'$1\'\'\'\'.</font>',
+'export-images'     => 'Экспортировать изображения',
+'export-selfcontained' => 'Включать содержимое изображений в экспортный файл',
 'export-download'   => 'Предложить сохранить как файл',
 'export-templates'  => 'Включить шаблоны',
-'export-pagelinks'  => 'Включить связанные страницы глубиной:',
+'export-pagelinks'  => 'Включить статьи, связанные ссылками',
+'export-closure'    => 'Включая подкатегории',
+'export-link-depth' => 'Максимальная глубина ссылок:',
 
 # Namespace 8 related
 'allmessages'                   => 'Системные сообщения',
@@ -2748,7 +2756,6 @@
 'import-comment'             => 'Примечание:',
 'importtext'                 => 'Пожалуйста, экспортируйте страницу из исходной вики, используя [[Special:Export|соответствующий инструмент]]. Сохраните файл на диск, а затем загрузите его сюда.',
 'importstart'                => 'Импортирование страниц…',
-'import-revision-count'      => '$1 {{PLURAL:$1|версия|версии|версий}}',
 'importnopages'              => 'Нет страниц для импортирования.',
 'imported-log-entries'       => '{{PLURAL:$1|Импортирована $1 запись журнала|Импортировано $1 записи журнала|Импортировано $1 записей журнала}}.',
 'importfailed'               => 'Не удалось импортировать: $1',
@@ -2765,9 +2772,15 @@
 'importuploaderrortemp'      => 'Не удалось загрузить или импортировать файл. Временная папка отсутствует.',
 'import-parse-failure'       => 'Ошибка разбора XML при импорте',
 'import-noarticle'           => 'Нет страницы для импортирования!',
-'import-nonewrevisions'      => 'Все редакции были ранее импортированы.',
 'xml-error-string'           => '$1 в строке $2, позиции $3 (байт $4): $5',
 'import-upload'              => 'Загрузить XML-данные',
+'import-norevisions'         => 'Нет редакций для импортирования.',
+'import-nonewrevisions-localnewer' => 'Все редакции были ранее импортированы. Страница изменена локально.',
+'import-nonewrevisions'      => 'Все редакции были ранее импортированы. Локальных изменений нет.',
+'import-revision-count'      => '$1 {{PLURAL:$1|версия|версии|версий}}.',
+'import-revision-count-newpage' => '$1 {{PLURAL:$1|версия|версии|версий}} (новая страница).',
+'import-conflict'            => '$1 {{PLURAL:$1|версия|версии|версий}} (конфликт: $2).',
+'import-conflict-difflink'   => '$1 (импорт) и $2 (локальная)',
 'import-token-mismatch'      => 'Потеряны данные сеанса. Пожалуйста, попробуйте ещё раз.',
 'import-invalid-interwiki'   => 'Невозможно импортировать из указанной вики.',
 
Index: languages/messages/MessagesEn.php
===================================================================
--- languages/messages/MessagesEn.php	(revision 82604)
+++ languages/messages/MessagesEn.php	(working copy)
@@ -3260,13 +3260,21 @@
 'exportnohistory'   => "----
 '''Note:''' Exporting the full history of pages through this form has been disabled due to performance reasons.",
 'export-submit'     => 'Export',
-'export-addcattext' => 'Add pages from category:',
+'export-addpages'   => "'''Add pages:'''",
 'export-addcat'     => 'Add',
-'export-addnstext'  => 'Add pages from namespace:',
-'export-addns'      => 'Add',
+'export-catname'    => 'Category:',
+'export-modifydate' => 'Changed after:',
+'export-namespace'  => 'Namespace:',
+'export-invalid-catname' => '<font color=red>\'\'\'Unknown category ignored: \'$1\'\'\'\'.</font>',
+'export-invalid-namespace' => '<font color=red>\'\'\'Unknown namespace ignored: \'$1\'\'\'\'.</font>',
+'export-invalid-modifydate' => '<font color=red>\'\'\'Incorrect timestamp ignored (use format <u>YYYY-MM-DD HH:MM:SS</u>): \'$1\'\'\'\'.</font>',
+'export-images'     => 'Export images',
+'export-selfcontained' => 'Include image contents into the export file',
 'export-download'   => 'Save as file',
 'export-templates'  => 'Include templates',
-'export-pagelinks'  => 'Include linked pages to a depth of:',
+'export-pagelinks'  => 'Include linked articles',
+'export-closure'    => 'Include subcategories',
+'export-link-depth' => 'Maximum link depth:',
 
 # Namespace 8 related
 'allmessages'                   => 'System messages',
@@ -3313,7 +3321,6 @@
 'importtext'                 => 'Please export the file from the source wiki using the [[Special:Export|export utility]].
 Save it to your computer and upload it here.',
 'importstart'                => 'Importing pages...',
-'import-revision-count'      => '$1 {{PLURAL:$1|revision|revisions}}',
 'importnopages'              => 'No pages to import.',
 'imported-log-entries'       => 'Imported $1 {{PLURAL:$1|log entry|log entries}}.',
 'importfailed'               => 'Import failed: <nowiki>$1</nowiki>',
@@ -3333,9 +3340,15 @@
 A temporary folder is missing.',
 'import-parse-failure'       => 'XML import parse failure',
 'import-noarticle'           => 'No page to import!',
-'import-nonewrevisions'      => 'All revisions were previously imported.',
 'xml-error-string'           => '$1 at line $2, col $3 (byte $4): $5',
 'import-upload'              => 'Upload XML data',
+'import-norevisions'         => 'No revisions to import.',
+'import-nonewrevisions-localnewer' => 'All revisions were previously imported. Page changed locally.',
+'import-nonewrevisions'      => 'All revisions were previously imported. No local changes.',
+'import-revision-count'      => '$1 {{PLURAL:$1|revision|revisions}}',
+'import-revision-count-newpage' => '$1 {{PLURAL:$1|revision|revisions}} (new page)',
+'import-conflict'            => '$1 {{PLURAL:$1|revision|revisions}} (conflict: $2)',
+'import-conflict-difflink'   => '$1 (imported) и $2 (local)',
 'import-token-mismatch'      => 'Loss of session data.
 Please try again.',
 'import-invalid-interwiki'   => 'Cannot import from the specified wiki.',
