# User Vitaliy Filippov <vitalif@yourcmc.ru>
# Date 1302184764 -10800

Totally improved MediaWiki Import and Export engine with conflict detection,
advanced export page list building options and support for exporting file data
over HTTP or inside the export file.

Requires running file-upload-renamer.php when applied to a non-empty MediaWiki
installation.

Signed-off-by: Vitaliy Filippov <vitalif@yourcmc.ru>

Index: skins/common/shared.css
===================================================================
--- skins/common/shared.css	(revision 85617)
+++ skins/common/shared.css	(working copy)
@@ -262,6 +262,8 @@
 	font-size: 90%;
 }
 
+.addpages div { display: inline-block; text-align: right; vertical-align: top; padding-right: 8px; }
+
 /* (show/hide) revision deletion links */
 span.mw-revdelundel-link,
 strong.mw-revdelundel-link {
Index: includes/filerepo/LocalFile.php
===================================================================
--- includes/filerepo/LocalFile.php	(revision 85617)
+++ includes/filerepo/LocalFile.php	(working copy)
@@ -857,6 +857,64 @@
 	}
 
 	/**
+	 * Upload a file directly into archive. Generally for Special:Import
+	 */
+	function uploadIntoArchive( $srcPath, $comment, $pageText, $flags = 0, $props = false, $timestamp = false, $user = NULL )
+	{
+		$this->lock();
+		$dstName = $this->generateArchiveName( $timestamp );
+		$status = $this->publish( $srcPath, $flags, $dstName );
+		if ( $status->ok ) {
+			if ( !$this->recordOldUpload( $dstName, $comment, $pageText, $props, $timestamp, $user ) ) {
+				$status->fatal( 'filenotfound', $srcPath );
+			}
+		}
+		$this->unlock();
+		return $status;
+	}
+
+	/**
+	 * Record a file upload in the upload log and the oldimage table
+	 */
+	function recordOldUpload( $dstName, $comment, $pageText, $props = false, $timestamp = false, $user = NULL )
+	{
+		$dbw = $this->repo->getMasterDB();
+
+		$dstPath = $this->repo->getZonePath('public') . '/archive/' . $this->getHashPath() . $dstName;
+		$props = self::getPropsFromPath( $dstPath );
+		if (!$props['fileExists'])
+			return false;
+
+		$props['timestamp'] = $dbw->timestamp( $timestamp );
+		list($props['major_mime'], $props['minor_mime']) =
+			self::splitMime( "{$props['major_mime']}/{$props['minor_mime']}" );
+
+		$dbw->insert( 'oldimage',
+			array(
+				'oi_name'         => $this->getName(),
+				'oi_archive_name' => $dstName,
+				'oi_size'         => $props['size'],
+				'oi_width'        => intval($props['width']),
+				'oi_height'       => intval($props['height']),
+				'oi_bits'         => $props['bits'],
+				'oi_timestamp'    => $props['timestamp'],
+				'oi_description'  => $comment,
+				'oi_user'         => $user->getId(),
+				'oi_user_text'    => $user->getName(),
+				'oi_metadata'     => $props['metadata'],
+				'oi_media_type'   => $props['media_type'],
+				'oi_major_mime'   => $props['major_mime'],
+				'oi_minor_mime'   => $props['minor_mime'],
+				'oi_sha1'         => $props['sha1'],
+			), __METHOD__
+		);
+
+		$dbw->immediateCommit();
+
+		return true;
+	}
+
+	/**
 	 * Record a file upload in the upload log and the image table
 	 */
 	function recordUpload2(
@@ -1037,6 +1095,13 @@
 
 	/**
 	 * Move or copy a file to its public location. If a file exists at the
+	 */
+	function generateArchiveName( $timestamp ) {
+		return gmdate( 'YmdHis', wfTimestamp( TS_UNIX, $timestamp ) ) . '!'. $this->getName();
+	}
+
+	/**
+	 * Move or copy a file to its public location. If a file exists at the
 	 * destination, move it to an archive. Returns a FileRepoStatus object with
 	 * the archive name in the "value" member on success.
 	 *
@@ -1045,16 +1110,22 @@
 	 *
 	 * @param $srcPath String: local filesystem path to the source image
 	 * @param $flags Integer: a bitwise combination of:
-	 *     File::DELETE_SOURCE    Delete the source file, i.e. move
-	 *         rather than copy
+	 *     File::DELETE_SOURCE       Delete the source file, i.e. move rather than copy
+	 * @param string $dstName Local wanted path (for example some archive
+	 *        path to publish image into the archive directly)
 	 * @return FileRepoStatus object. On success, the value member contains the
 	 *     archive name, or an empty string if it was a new file.
 	 */
-	function publish( $srcPath, $flags = 0 ) {
+	function publish( $srcPath, $flags = 0, $dstName = NULL ) {
 		$this->lock();
 
-		$dstRel = $this->getRel();
-		$archiveName = gmdate( 'YmdHis' ) . '!' . $this->getName();
+		if (!$dstName)
+			$dstRel = $this->getRel();
+		else
+			$dstRel = 'archive/' . $this->getHashPath() . $dstName;
+		/* Original gmdate( 'YmdHis' ) is not corrent AT ALL! */
+		/* It gives an inconsistency: file name has one timestamp and database row has another. */
+		$archiveName = $this->generateArchiveName( $this->getTimestamp() );
 		$archiveRel = 'archive/' . $this->getHashPath() . $archiveName;
 		$flags = $flags & File::DELETE_SOURCE ? LocalRepo::DELETE_SOURCE : 0;
 		$status = $this->repo->publish( $srcPath, $dstRel, $archiveRel, $flags );
Index: includes/Export.php
===================================================================
--- includes/Export.php	(revision 85617)
+++ includes/Export.php	(working copy)
@@ -3,6 +3,7 @@
  * Base classes for dumps and export
  *
  * Copyright © 2003, 2005, 2006 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  * http://www.mediawiki.org/
  *
  * This program is free software; you can redistribute it and/or modify
@@ -34,7 +35,8 @@
 	var $list_authors = false ; # Return distinct author list (when not returning full history)
 	var $author_list = "" ;
 
-	var $dumpUploads = false;
+	var $dumpUploads = false;   # Dump uploaded files into the export file
+	var $selfContained = false; # Make export file self-contained (multipart/related)
 
 	const FULL = 1;
 	const CURRENT = 2;
@@ -85,6 +87,7 @@
 	}
 
 	public function openStream() {
+		$this->writer->multipart = $this->dumpUploads && $this->selfContained;
 		$output = $this->writer->openStream();
 		$this->sink->writeOpenStream( $output );
 	}
@@ -92,6 +95,9 @@
 	public function closeStream() {
 		$output = $this->writer->closeStream();
 		$this->sink->writeCloseStream( $output );
+		/* Dump $this->writer->binaries into multipart/related */
+		while ($part = $this->writer->nextPart())
+			$this->sink->writePart($part);
 	}
 
 	/**
@@ -313,7 +319,8 @@
 				if( isset( $last ) ) {
 					$output = '';
 					if( $this->dumpUploads ) {
-						$output .= $this->writer->writeUploads( $last );
+						$output .= $this->writer->writeUploads( $last,
+							$this->history == WikiExporter::CURRENT ? 1 : null );
 					}
 					$output .= $this->writer->closePage();
 					$this->sink->writeClosePage( $output );
@@ -328,7 +335,8 @@
 		if( isset( $last ) ) {
 			$output = '';
 			if( $this->dumpUploads ) {
-				$output .= $this->writer->writeUploads( $last );
+				$output .= $this->writer->writeUploads( $last,
+					$this->history == WikiExporter::CURRENT ? 1 : null );
 			}
 			$output .= $this->author_list;
 			$output .= $this->writer->closePage();
@@ -349,6 +357,12 @@
  */
 class XmlDumpWriter {
 
+	var $boundary;
+	var $binaries;
+	var $multipart;
+
+	var $currentpart;
+
 	/**
 	 * Returns the export schema version.
 	 * @return string
@@ -370,7 +384,15 @@
 	function openStream() {
 		global $wgLanguageCode;
 		$ver = $this->schemaVersion();
-		return Xml::element( 'mediawiki', array(
+		$mp = '';
+		if ($this->multipart)
+		{
+			$this->boundary = '--'.time();
+			$this->binaries = array();
+			$mp = "Content-Type: multipart/related; boundary=".$this->boundary."\n".$this->boundary."\nContent-Type: text/xml\nContent-ID: Revisions\n\n";
+		}
+		return $mp . "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n" .
+			Xml::element( 'mediawiki', array(
 			'xmlns'              => "http://www.mediawiki.org/xml/export-$ver/",
 			'xmlns:xsi'          => "http://www.w3.org/2001/XMLSchema-instance",
 			'xsi:schemaLocation' => "http://www.mediawiki.org/xml/export-$ver/ " .
@@ -437,6 +459,38 @@
 		return "</mediawiki>\n";
 	}
 
+	function nextPart()
+	{
+		$data = '';
+		if ( !$this->currentpart )
+		{
+			if ( !$this->multipart || !count( $this->binaries ) )
+				return '';
+			list( $name ) = array_keys( $this->binaries );
+			$filename = $this->binaries[ $name ];
+			unset( $this->binaries[ $name ] );
+			$fp = @fopen( $filename, "rb" );
+			if ( !$fp )
+				return $this->nextPart();
+			$this->currentpart = array(
+				'name' => $name,
+				'filename' => $filename,
+				'fp' => $fp,
+			);
+			$data = $this->boundary.
+				"\nContent-Type: application/binary\n" .
+				"Content-Transfer-Encoding: Little-Endian\n" .
+				"Content-ID: $name\n" .
+				"Content-Length: ".filesize($filename)."\n\n";
+		}
+		$data .= @fread( $this->currentpart['fp'], 1048576 );
+		if ( @feof( $this->currentpart['fp'] ) )
+		{
+			@fclose( $this->currentpart['fp'] );
+			$this->currentpart = NULL;
+		}
+		return $data;
+	}
 
 	/**
 	 * Opens a <page> section on the output stream, with data
@@ -595,13 +649,15 @@
 	/**
 	 * Warning! This data is potentially inconsistent. :(
 	 */
-	function writeUploads( $row ) {
+	function writeUploads( $row, $limit = null ) {
 		if( $row->page_namespace == NS_IMAGE ) {
 			$img = wfFindFile( $row->page_title );
 			if( $img ) {
 				$out = '';
-				foreach( array_reverse( $img->getHistory() ) as $ver ) {
-					$out .= $this->writeUpload( $ver );
+				if ( !$limit || $limit > 1 ) {
+					foreach( $img->getHistory( $limit ? $limit-1 : NULL ) as $ver ) {
+						$out .= $this->writeUpload( $ver );
+					}
 				}
 				$out .= $this->writeUpload( $img );
 				return $out;
@@ -611,13 +667,22 @@
 	}
 
 	function writeUpload( $file ) {
+		if ( !$file->exists() )
+			return "";
+		if ( $this->multipart )
+		{
+			$partname = $file->isOld() ? $file->getArchiveName() : $file->getName();
+			$this->binaries[ $partname ] = $file->getPath();
+		}
 		return "    <upload>\n" .
 			$this->writeTimestamp( $file->getTimestamp() ) .
 			$this->writeContributor( $file->getUser( 'id' ), $file->getUser( 'text' ) ) .
-			"      " . Xml::elementClean( 'comment', null, $file->getDescription() ) . "\n" .
-			"      " . Xml::element( 'filename', null, $file->getName() ) . "\n" .
-			"      " . Xml::element( 'src', null, $file->getFullUrl() ) . "\n" .
-			"      " . Xml::element( 'size', null, $file->getSize() ) . "\n" .
+			"      " . Xml::ElementClean( 'comment', null, $file->getDescription() ) . "\n" .
+			"      " . Xml::Element( 'filename', null, $file->getName() ) . "\n" .
+			"      " . Xml::Element( 'src',
+			                      array('sha1' => $file->getSha1()),
+			                      $this->multipart ? "multipart://$partname" : $file->getFullUrl() ) . "\n" .
+			"      " . Xml::Element( 'size', null, $file->getSize() ) . "\n" .
 			"    </upload>\n";
 	}
 
@@ -653,6 +718,10 @@
 		$this->write( $string );
 	}
 
+	function writePart( $string ) {
+		$this->write( $string );
+	}
+
 	/**
 	 * Override to write to a different stream type.
 	 * @return bool
Index: includes/specials/SpecialImport.php
===================================================================
--- includes/specials/SpecialImport.php	(revision 85617)
+++ includes/specials/SpecialImport.php	(working copy)
@@ -3,6 +3,7 @@
  * Implements Special:Import
  *
  * Copyright © 2003,2005 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  * http://www.mediawiki.org/
  *
  * This program is free software; you can redistribute it and/or modify
@@ -357,12 +358,56 @@
 		$localCount = $wgLang->formatNum( $successCount );
 		$contentCount = $wgContLang->formatNum( $successCount );
 
+		/* No revisions in import */
+		if (!$pageInfo['lastExistingRevision'] && $successCount == 0)
+			$msg = wfMsgHtml('import-norevisions');
+
+		/* New page imported */
+		else if (!$pageInfo['lastLocalRevision'] && $successCount > 0)
+			$msg = wfMsgExt('import-revision-count-newpage', array('parsemag', 'escape'), $localCount);
+
+		else
+		{
+			$newer = !$pageInfo['lastExistingRevision'] ||
+				$pageInfo['lastLocalRevision']->getTimestamp() > $pageInfo['lastExistingRevision']->getTimestamp();
+			if ($successCount > 0)
+			{
+				/* Conflict */
+				if ($newer)
+				{
+					$linktext = wfMsgExt( 'import-conflict-difflink',
+						array( 'parsemag', 'escape' ),
+						$pageInfo['lastRevision']->getId(),
+						$pageInfo['lastLocalRevision']->getId() );
+					$link = $skin->makeKnownLinkObj(
+						$title, $linktext,
+						'diff=' . $pageInfo['lastRevision']->getId() .
+						"&oldid=" . $pageInfo['lastLocalRevision']->getId() );
+					$msg = wfMsgExt( 'import-conflict',
+						array( 'parsemag' ),
+						$localCount,
+						$link );
+				}
+				/* Page history continued with new revisions */
+				else
+					$msg = wfMsgExt('import-revision-count', array('parsemag', 'escape'), $localCount);
+			}
+			else
+			{
+				/* Local revision is newer */
+				if ($newer)
+					$msg = wfMsgHtml('import-nonewrevisions-localnewer');
+				/* No changes nowhere */
+				else
+					$msg = wfMsgHtml('import-nonewrevisions');
+			}
+		}
+
+		$msg = $skin->makeKnownLinkObj( $title ) . ': ' . $msg;
+
+		$wgOut->addHtml( "<li>$msg</li>" );
+
 		if( $successCount > 0 ) {
-			$wgOut->addHTML( "<li>" . $skin->linkKnown( $title ) . " " .
-				wfMsgExt( 'import-revision-count', array( 'parsemag', 'escape' ), $localCount ) .
-				"</li>\n"
-			);
-
 			$log = new LogPage( 'import' );
 			if( $this->mIsUpload ) {
 				$detail = wfMsgExt( 'import-logentry-upload-detail', array( 'content', 'parsemag' ),
@@ -381,19 +426,9 @@
 				}
 				$log->addEntry( 'interwiki', $title, $detail );
 			}
-
-			$comment = $detail; // quick
-			$dbw = wfGetDB( DB_MASTER );
-			$latest = $title->getLatestRevID();
-			$nullRevision = Revision::newNullRevision( $dbw, $title->getArticleId(), $comment, true );
-			$nullRevision->insertOn( $dbw );
-			$article = new Article( $title );
-			# Update page record
-			$article->updateRevisionOn( $dbw, $nullRevision );
-			wfRunHooks( 'NewRevisionFromEditComplete', array($article, $nullRevision, $latest, $wgUser) );
-		} else {
-			$wgOut->addHTML( "<li>" . $skin->linkKnown( $title ) . " " .
-				wfMsgHtml( 'import-nonewrevisions' ) . "</li>\n" );
+			// [MediaWiki4Intranet] do not insert any empty revisions because it leads
+			// to fancy bugs (infinitely multiplicated revisions) in the case of cross
+			// (2-way) import-export.
 		}
 	}
 
Index: includes/specials/SpecialExport.php
===================================================================
--- includes/specials/SpecialExport.php	(revision 85617)
+++ includes/specials/SpecialExport.php	(working copy)
@@ -3,6 +3,7 @@
  * Implements Special:Export
  *
  * Copyright © 2003-2008 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
@@ -28,9 +29,10 @@
  *
  * @ingroup SpecialPage
  */
+
 class SpecialExport extends SpecialPage {
 
-	private $curonly, $doExport, $pageLinkDepth, $templates;
+	private $curonly, $doExport, $linkDepth, $templates;
 	private $images;
 
 	public function __construct() {
@@ -50,44 +52,17 @@
 		$this->doExport = false;
 		$this->templates = $wgRequest->getCheck( 'templates' );
 		$this->images = $wgRequest->getCheck( 'images' ); // Doesn't do anything yet
-		$this->pageLinkDepth = $this->validateLinkDepth(
-			$wgRequest->getIntOrNull( 'pagelink-depth' )
-		);
+		$this->linkDepth = $this->validateLinkDepth(
+			$wgRequest->getIntOrNull( 'link-depth' ) );
 		$nsindex = '';
 
-		if ( $wgRequest->getCheck( 'addcat' ) ) {
-			$page = $wgRequest->getText( 'pages' );
-			$catname = $wgRequest->getText( 'catname' );
-
-			if ( $catname !== '' && $catname !== null && $catname !== false ) {
-				$t = Title::makeTitleSafe( NS_MAIN, $catname );
-				if ( $t ) {
-					/**
-					 * @todo Fixme: this can lead to hitting memory limit for very large
-					 * categories. Ideally we would do the lookup synchronously
-					 * during the export in a single query.
-					 */
-					$catpages = $this->getPagesFromCategory( $t );
-					if ( $catpages ) {
-						$page .= "\n" . implode( "\n", $catpages );
-					}
-				}
-			}
+		$state = $wgRequest->getValues();
+		$state['errors'] = array();
+		if ($state['addcat'])
+		{
+			self::addPagesExec($state);
+			$page = $state['pages'];
 		}
-		else if( $wgRequest->getCheck( 'addns' ) && $wgExportFromNamespaces ) {
-			$page = $wgRequest->getText( 'pages' );
-			$nsindex = $wgRequest->getText( 'nsindex', '' );
-
-			if ( strval( $nsindex ) !== ''  ) {
-				/**
-				 * Same implementation as above, so same @todo
-				 */
-				$nspages = $this->getPagesFromNamespace( $nsindex );
-				if ( $nspages ) {
-					$page .= "\n" . implode( "\n", $nspages );
-				}
-			}
-		}
 		else if( $wgRequest->wasPosted() && $par == '' ) {
 			$page = $wgRequest->getText( 'pages' );
 			$this->curonly = $wgRequest->getCheck( 'curonly' );
@@ -174,13 +149,10 @@
 
 		$form = Xml::openElement( 'form', array( 'method' => 'post',
 			'action' => $this->getTitle()->getLocalUrl( 'action=submit' ) ) );
-		$form .= Xml::inputLabel( wfMsg( 'export-addcattext' )    , 'catname', 'catname', 40 ) . '&#160;';
-		$form .= Xml::submitButton( wfMsg( 'export-addcat' ), array( 'name' => 'addcat' ) ) . '<br />';
+		foreach ($state['errors'] as $e)
+			$form .= wfMsgExt($e[0], array('parse'), $e[1]);
 
-		if ( $wgExportFromNamespaces ) {
-			$form .= Xml::namespaceSelector( $nsindex, null, 'nsindex', wfMsg( 'export-addnstext' ) ) . '&#160;';
-			$form .= Xml::submitButton( wfMsg( 'export-addns' ), array( 'name' => 'addns' ) ) . '<br />';
-		}
+		$form .= self::addPagesForm($state);
 
 		$form .= Xml::element( 'textarea', array( 'name' => 'pages', 'cols' => 40, 'rows' => 10 ), $page, false );
 		$form .= '<br />';
@@ -190,30 +162,27 @@
 				wfMsg( 'exportcuronly' ),
 				'curonly',
 				'curonly',
-				$wgRequest->wasPosted() ? $wgRequest->getCheck( 'curonly' ) : true
+				$wgRequest->getCheck('curonly') ? true : false
 			) . '<br />';
 		} else {
 			$wgOut->addHTML( wfMsgExt( 'exportnohistory', 'parse' ) );
 		}
 
-		$form .= Xml::checkLabel(
-			wfMsg( 'export-templates' ),
-			'templates',
-			'wpExportTemplates',
-			$wgRequest->wasPosted() ? $wgRequest->getCheck( 'templates' ) : false
-		) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-templates' ), 'templates', 'wpExportTemplates', $wgRequest->getCheck('templates') ? true : false ) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-pagelinks' ), 'pagelinks', 'wpExportPagelinks', $wgRequest->getCheck('pagelinks') ? true : false ) . '<br />';
 
-		if( $wgExportMaxLinkDepth || $this->userCanOverrideExportDepth() ) {
-			$form .= Xml::inputLabel( wfMsg( 'export-pagelinks' ), 'pagelink-depth', 'pagelink-depth', 20, 0 ) . '<br />';
-		}
 		// Enable this when we can do something useful exporting/importing image information. :)
-		//$form .= Xml::checkLabel( wfMsg( 'export-images' ), 'images', 'wpExportImages', false ) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-images' ), 'images', 'wpExportImages', $wgRequest->getCheck('images') ? true : false ) . '<br />';
 		$form .= Xml::checkLabel(
 			wfMsg( 'export-download' ),
 			'wpDownload',
 			'wpDownload',
 			$wgRequest->wasPosted() ? $wgRequest->getCheck( 'wpDownload' ) : true
 		) . '<br />';
+		$form .= Xml::checkLabel( wfMsg( 'export-selfcontained' ), 'selfcontained', 'wpSelfContained', $wgRequest->getCheck('selfcontained') ? true : false ) . '<br />';
+		if( $wgExportMaxLinkDepth || $this->userCanOverrideExportDepth() ) {
+			$form .= Xml::inputLabel( wfMsg( 'export-link-depth' ), 'link-depth', 'link-depth', 20, $wgRequest->getVal('link-depth') ) . '<br />';
+		}
 
 		$form .= Xml::submitButton( wfMsg( 'export-submit' ), $wgUser->getSkin()->tooltipAndAccessKeyAttribs( 'export' ) );
 		$form .= Xml::closeElement( 'form' );
@@ -235,6 +204,9 @@
 	 *                      not returning full history)
 	 */
 	private function doExport( $page, $history, $list_authors ) {
+		global $wgRequest;
+
+		$inputPages = array(); // Set of original pages to pass on to further manipulation...
 		$pageSet = array(); // Inverted index of all pages to look up
 
 		// Split up and normalize input
@@ -243,38 +215,31 @@
 			$title = Title::newFromText( $pageName );
 			if( $title && $title->getInterwiki() == '' && $title->getText() !== '' ) {
 				// Only record each page once!
+				$inputPages[] = $title;
 				$pageSet[$title->getPrefixedText()] = true;
 			}
 		}
 
-		// Set of original pages to pass on to further manipulation...
-		$inputPages = array_keys( $pageSet );
-
 		// Look up any linked pages if asked...
-		if( $this->templates ) {
-			$pageSet = $this->getTemplates( $inputPages, $pageSet );
-		}
-		$linkDepth = $this->pageLinkDepth;
-		if( $linkDepth ) {
-			$pageSet = $this->getPageLinks( $inputPages, $pageSet, $linkDepth );
-		}
+		$t = $wgRequest->getCheck( 'templates' ) ? 1 : 0;
+		$p = $wgRequest->getCheck( 'pagelinks' ) ? 1 : 0;
+		$i = $wgRequest->getCheck( 'images' ) ? 1 : 0;
+		$step = 0;
+		do
+		{
+			$added = 0;
+			if( $t ) $added += self::getTemplates( $inputPages, $pageSet );
+			if( $p ) $added += self::getPagelinks( $inputPages, $pageSet );
+			if( $i ) $added += self::getImages( $inputPages, $pageSet );
+			$step++;
+		} while( $t+$p+$i > 1 && $added > 0 && ( !$this->linkDepth || $step < $this->linkDepth ) );
 
-		/*
-		 // Enable this when we can do something useful exporting/importing image information. :)
-		 if( $this->images ) ) {
-		 $pageSet = $this->getImages( $inputPages, $pageSet );
-		 }
-		 */
+		$pages = array();
+		/* Bug 8824: Only export pages the user can read */
+		foreach ( $inputPages as $title )
+			if ( $title->userCanRead() )
+				$pages[] = $title;
 
-		$pages = array_keys( $pageSet );
-
-		// Normalize titles to the same format and remove dupes, see bug 17374
-		foreach( $pages as $k => $v ) {
-			$pages[$k] = str_replace( " ", "_", $v );
-		}
-
-		$pages = array_unique( $pages );
-
 		/* Ok, let's get to it... */
 		if( $history == WikiExporter::CURRENT ) {
 			$lb = false;
@@ -294,30 +259,11 @@
 
 		$exporter = new WikiExporter( $db, $history, $buffer );
 		$exporter->list_authors = $list_authors;
+		$exporter->dumpUploads = $wgRequest->getCheck('images') ? true : false;
+		$exporter->selfContained = $wgRequest->getCheck('selfcontained') ? true : false;
 		$exporter->openStream();
 
-		foreach( $pages as $page ) {
-			/*
-			 if( $wgExportMaxHistory && !$this->curonly ) {
-			 $title = Title::newFromText( $page );
-			 if( $title ) {
-			 $count = Revision::countByTitle( $db, $title );
-			 if( $count > $wgExportMaxHistory ) {
-			 wfDebug( __FUNCTION__ .
-			 ": Skipped $page, $count revisions too big\n" );
-			 continue;
-			 }
-			 }
-			 }*/
-			#Bug 8824: Only export pages the user can read
-			$title = Title::newFromText( $page );
-			if( is_null( $title ) ) {
-				continue; #TODO: perhaps output an <error> tag or something.
-			}
-			if( !$title->userCanRead() ) {
-				continue; #TODO: perhaps output an <error> tag or something.
-			}
-
+		foreach( $pages as $title ) {
 			$exporter->pageByTitle( $title );
 		}
 
@@ -328,58 +274,96 @@
 		}
 	}
 
-	private function getPagesFromCategory( $title ) {
-		global $wgContLang;
+	static function addPagesExec(&$state)
+	{
+		$catname = $state['catname'];
+		$modifydate = $state['modifydate'];
+		$namespace = $state['namespace'];
+		$closure = $state['closure'];
+		$catpages = self::getPagesFromCategory($catname, $modifydate, $namespace, $closure);
+		if ($catpages)
+		{
+			foreach ($catpages as $title)
+			{
+/*op-patch|TS|2010-04-26|HaloACL|SafeTitle|start*/
+				if (!method_exists($title, 'userCanReadEx') || $title->userCanReadEx())
+/*op-patch|TS|2010-04-26|end*/
+					$state['pages'] .= "\n" . $title->getPrefixedText();
+			}
+		}
+		$state['errors'] = array();
+		if (!$catname && strlen($state['catname']))
+			$state['errors'][] = array('export-invalid-catname', $state['catname']);
+		if ($modifydate)
+			$state['modifydate'] = wfTimestamp(TS_DB, $modifydate);
+		else if ($state['modifydate'])
+			$state['errors'][] = array('export-invalid-modifydate', $state['modifydate']);
+		if (!$namespace && strlen($state['namespace']))
+			$state['errors'][] = array('export-invalid-namespace', $state['namespace']);
+	}
 
-		$name = $title->getDBkey();
+	static function addPagesForm($state)
+	{
+		$form .= '<fieldset class="addpages">';
+		$form .= '<legend>' . wfMsgExt('export-addpages', 'parse') . '</legend>';
+		$form .= '<div class="ap_catname">' . Xml::inputLabel(wfMsg('export-catname'), 'catname', 'catname', 40, $state['catname']) .
+		         '<br />' . Xml::checkLabel(wfMsg('export-closure'), 'closure', 'wpExportClosure', $state['closure'] ? true : false) . '</div>';
+		$form .= '<div class="ap_namespace">' . Xml::inputLabel(wfMsg('export-namespace'), 'namespace', 'namespace', 20, $state['namespace']) . '</div>';
+		$form .= '<div class="ap_modifydate">' . Xml::inputLabel(wfMsg('export-modifydate'), 'modifydate', 'modifydate', 20, $state['modifydate']) . '</div>';
+		$form .= '<div class="ap_submit">' . Xml::submitButton(wfMsg('export-addcat'), array('name' => 'addcat')) . '</div>';
+		$form .= '</fieldset>';
+		return $form;
+	}
 
-		$dbr = wfGetDB( DB_SLAVE );
-		$res = $dbr->select(
-			array( 'page', 'categorylinks' ),
-			array( 'page_namespace', 'page_title' ),
-			array( 'cl_from=page_id', 'cl_to' => $name ),
-			__METHOD__,
-			array( 'LIMIT' => '5000' )
-		);
-
+	static function getPagesFromCategory(&$catname, &$modifydate, &$namespace, $closure)
+	{
+		if (!strlen($catname) || !($catname = Title::makeTitleSafe(NS_CATEGORY, $catname)))
+			$catname = NULL;
+		else
+			$catname = $catname->getDbKey();
+		if (!strlen($modifydate) || !($modifydate = wfTimestampOrNull(TS_MW, $modifydate)))
+			$modifydate = NULL;
+		if (!strlen($namespace) || !($namespace = Title::newFromText("$namespace:A", NS_MAIN)))
+			$namespace = NULL;
+		else
+			$namespace = $namespace->getNamespace();
 		$pages = array();
-
-		foreach ( $res as $row ) {
-			$n = $row->page_title;
-			if ($row->page_namespace) {
-				$ns = $wgContLang->getNsText( $row->page_namespace );
-				$n = $ns . ':' . $n;
-			}
-
-			$pages[] = $n;
-		}
-		return $pages;
+		self::rgetPagesFromCategory($catname, $modifydate, $namespace, $closure, $pages);
+		return array_values($pages);
 	}
 
-	private function getPagesFromNamespace( $nsindex ) {
+	static function rgetPagesFromCategory($catname, $modifydate, $namespace, $closure, &$pages)
+	{
 		global $wgContLang;
+		$dbr = wfGetDB(DB_SLAVE);
+		$from = array('page');
+		$where = array();
 
-		$dbr = wfGetDB( DB_SLAVE );
-		$res = $dbr->select(
-			'page',
-			array( 'page_namespace', 'page_title' ),
-			array( 'page_namespace' => $nsindex ),
-			__METHOD__,
-			array( 'LIMIT' => '5000' )
-		);
+		if (!is_null($catname))
+		{
+			$from[] = 'categorylinks';
+			$where[] = 'cl_from=page_id';
+			$where['cl_to'] = $catname;
+		}
 
-		$pages = array();
+		if (!is_null($modifydate))
+			$where[] = "page_touched>$modifydate";
 
-		foreach ( $res as $row ) {
-			$n = $row->page_title;
+		if (!is_null($namespace))
+			$where['page_namespace'] = $namespace;
 
-			if ( $row->page_namespace ) {
-				$ns = $wgContLang->getNsText( $row->page_namespace );
-				$n = $ns . ':' . $n;
+		$res = $dbr->select( $from, array( 'page_namespace', 'page_title' ), $where, __METHOD__ );
+		while ( $row = $dbr->fetchRow( $res ) )
+		{
+			$row = Title::makeTitleSafe( $row['page_namespace'], $row['page_title'] );
+			if ($row && !$pages[ $row->getArticleId() ] )
+			{
+				$pages[ $row->getArticleId() ] = $row;
+				if ( $closure && $row->getNamespace() == NS_CATEGORY )
+					self::rgetPagesFromCategory( $row->getDbKey(), $modifydate, $namespace, $closure, $pages );
 			}
-
-			$pages[] = $n;
 		}
+
 		return $pages;
 	}
 
@@ -389,8 +373,10 @@
 	 * @param $pageSet array, associative array indexed by titles for output
 	 * @return array associative array index by titles
 	 */
-	private function getTemplates( $inputPages, $pageSet ) {
-		return $this->getLinks( $inputPages, $pageSet,
+	private function getTemplates( &$inputPages, &$pageSet ) {
+		return $this->getLinks(
+			$inputPages,
+			$pageSet,
 			'templatelinks',
 			array( 'tl_namespace AS namespace', 'tl_title AS title' ),
 			array( 'page_id=tl_from' )
@@ -403,7 +389,7 @@
 	private function validateLinkDepth( $depth ) {
 		global $wgExportMaxLinkDepth;
 
-		if( $depth < 0 ) {
+		if( $depth <= 0 ) {
 			return 0;
 		}
 
@@ -413,26 +399,18 @@
 			}
 		}
 
-		/*
-		 * There's a HARD CODED limit of 5 levels of recursion here to prevent a
-		 * crazy-big export from being done by someone setting the depth
-		 * number too high. In other words, last resort safety net.
-		 */
-		return intval( min( $depth, 5 ) );
+		return $depth;
 	}
 
 	/** Expand a list of pages to include pages linked to from that page. */
-	private function getPageLinks( $inputPages, $pageSet, $depth ) {
-		for( ; $depth > 0; --$depth ) {
-			$pageSet = $this->getLinks(
-				$inputPages, $pageSet, 'pagelinks',
-				array( 'pl_namespace AS namespace', 'pl_title AS title' ),
-				array( 'page_id=pl_from' )
-			);
-			$inputPages = array_keys( $pageSet );
-		}
-
-		return $pageSet;
+	private function getPageLinks( &$inputPages, &$pageSet ) {
+		return $this->getLinks(
+			$inputPages,
+			$pageSet,
+			'pagelinks',
+			array( 'pl_namespace AS namespace', 'pl_title AS title' ),
+			array( 'page_id=pl_from' )
+		);
 	}
 
 	/**
@@ -443,7 +421,7 @@
 	 *
 	 * @return array associative array index by titles
 	 */
-	private function getImages( $inputPages, $pageSet ) {
+	private function getImages( &$inputPages, &$pageSet ) {
 		return $this->getLinks(
 			$inputPages,
 			$pageSet,
@@ -455,38 +433,35 @@
 
 	/**
 	 * Expand a list of pages to include items used in those pages.
+	 * @private
 	 */
-	private function getLinks( $inputPages, $pageSet, $table, $fields, $join ) {
+	private function getLinks( &$inputPages, &$pageSet, $table, $fields, $join ) {
 		$dbr = wfGetDB( DB_SLAVE );
-
-		foreach( $inputPages as $page ) {
-			$title = Title::newFromText( $page );
-
-			if( $title ) {
-				$pageSet[$title->getPrefixedText()] = true;
-				/// @todo Fixme: May or may not be more efficient to batch these
-				///        by namespace when given multiple input pages.
-				$result = $dbr->select(
-					array( 'page', $table ),
-					$fields,
-					array_merge(
-						$join,
-						array(
-							'page_namespace' => $title->getNamespace(),
-							'page_title' => $title->getDBkey()
-						)
-					),
-					__METHOD__
-				);
-
-				foreach( $result as $row ) {
-					$template = Title::makeTitle( $row->namespace, $row->title );
-					$pageSet[$template->getPrefixedText()] = true;
+		$byns = array();
+		foreach( $inputPages as $title )
+			$byns[$title->getNamespace()][] = $title->getDBkey();
+		$added = 0;
+		foreach( $byns as $ns => $titles )
+		{
+			$result = $dbr->select(
+				array( 'page', $table ),
+				$fields,
+				array_merge( $join, array(
+					'page_namespace' => $ns,
+					'page_title' => $titles ) ),
+				__METHOD__ );
+			foreach( $result as $row )
+			{
+				$add = Title::makeTitle( $row->namespace, $row->title );
+				if( $add && !$pageSet[ $add->getPrefixedText() ] )
+				{
+					$pageSet[ $add->getPrefixedText() ] = true;
+					$inputPages[] = $add;
+					$added++;
 				}
 			}
 		}
-
-		return $pageSet;
+		return $added;
 	}
 
 }
Index: includes/Import.php
===================================================================
--- includes/Import.php	(revision 85617)
+++ includes/Import.php	(working copy)
@@ -3,6 +3,7 @@
  * MediaWiki page data importer
  *
  * Copyright © 2003,2005 Brion Vibber <brion@pobox.com>
+ *           © 2010 Vitaliy Filippov <vitalif@mail.ru>
  * http://www.mediawiki.org/
  *
  * This program is free software; you can redistribute it and/or modify
@@ -32,6 +33,7 @@
  */
 class WikiImporter {
 	private $reader = null;
+	private $importSource;
 	private $mLogItemCallback, $mUploadCallback, $mRevisionCallback, $mPageCallback;
 	private $mSiteInfoCallback, $mTargetNamespace, $mPageOutCallback;
 	private $mDebug;
@@ -43,6 +45,7 @@
 		$this->reader = new XMLReader();
 
 		stream_wrapper_register( 'uploadsource', 'UploadSourceAdapter' );
+		$this->importSource = $source;
 		$id = UploadSourceAdapter::registerSource( $source );
 		$this->reader->open( "uploadsource://$id" );
 
@@ -189,13 +192,13 @@
 	}
 
 	/**
-	 * Dummy for now...
+	 * Per-revision file import callback, performs the upload.
+	 * @param $revision WikiRevision
+	 * @private
 	 */
 	public function importUpload( $revision ) {
-			   $revision->importUpload();
-		//$dbw = wfGetDB( DB_MASTER );
-		//return $dbw->deadlockLoop( array( $revision, 'importUpload' ) );
-		return false;
+		$dbw = wfGetDB( DB_MASTER );
+		return $dbw->deadlockLoop( array( $revision, 'importUpload' ) );
 	}
 
 	/**
@@ -249,6 +252,16 @@
 	}
 
 	/**
+	 * Notify the callback function when a </upload> is closed.
+	 */
+	private function uploadCallback( $revision ) {
+		if( isset( $this->mUploadCallback ) ) {
+			$args = func_get_args();
+			call_user_func_array( $this->mUploadCallback, $args );
+		}
+	}
+
+	/**
 	 * Notify the callback function of a revision
 	 * @param $revision A WikiRevision object
 	 */
@@ -454,10 +467,36 @@
 		return $this->logItemCallback( $revision );
 	}
 
+	static function getLastLocalRevision( $title )
+	{
+		/* We need to skip import-info Null Revisions.
+		   They have rev_text_id equal to previous revision. */
+		$dbr = wfGetDB( DB_MASTER );
+		$res = $dbr->select( 'revision', 'rev_id, rev_text_id',
+			array( 'rev_page' => $title->getArticleId(), 'rev_len IS NOT NULL' ),
+			__METHOD__,
+			array( 'ORDER BY' => 'rev_timestamp DESC' ) );
+		$row = $res->fetchRow();
+		$rev_id = $row['rev_id'];
+		$text_id = $row['rev_text_id'];
+		while (($row = $res->fetchRow()) && $text_id == $row['rev_text_id'])
+			$rev_id = $row['rev_id'];
+		$res->free();
+		if ($rev_id)
+			return Revision::newFromId( $rev_id );
+		return NULL;
+	}
+
 	private function handlePage() {
 		// Handle page data.
 		$this->debug( "Enter page handler." );
-		$pageInfo = array( 'revisionCount' => 0, 'successfulRevisionCount' => 0 );
+		$pageInfo = array(
+			'revisionCount' => 0,
+			'successfulRevisionCount' => 0,
+			'lastRevision' => NULL,
+			'lastLocalRevision' => NULL,
+			'lastExistingRevision' => NULL,
+		);
 
 		// Fields that can just be stuffed in the pageInfo object
 		$normalFields = array( 'title', 'id', 'redirect', 'restrictions' );
@@ -491,6 +530,7 @@
 
 					$this->pageCallback( $title );
 					list( $pageInfo['_title'], $origTitle ) = $title;
+					$pageInfo['lastLocalRevision'] = self::getLastLocalRevision( $pageInfo['_title'] );
 				}
 			} elseif ( $tag == 'revision' ) {
 				$this->handleRevision( $pageInfo );
@@ -538,8 +578,15 @@
 		}
 
 		$pageInfo['revisionCount']++;
-		if ( $this->processRevision( $pageInfo, $revisionInfo ) ) {
-			$pageInfo['successfulRevisionCount']++;
+		if ( $r = $this->processRevision( $pageInfo, $revisionInfo ) ) {
+			if ( is_object($r) && $r->_imported )
+			{
+				$pageInfo['successfulRevisionCount']++;
+				$pageInfo['lastRevision'] = $r;
+			}
+			elseif ( is_object($r) && ( !$pageInfo['lastExistingRevision'] ||
+				$r->getTimestamp() > $pageInfo['lastExistingRevision']->getTimestamp() ) )
+				$pageInfo['lastExistingRevision'] = $r;
 		}
 	}
 
@@ -599,6 +646,8 @@
 				// Do nothing
 			} elseif ( in_array( $tag, $normalFields ) ) {
 				$uploadInfo[$tag] = $this->nodeContents();
+				if ( $tag == 'src' && $this->workRevision && ( $sha1 = $this->reader->getAttribute('sha1') ) )
+					$uploadInfo['sha1'] = $sha1;
 			} elseif ( $tag == 'contributor' ) {
 				$uploadInfo['contributor'] = $this->handleContributor();
 			} elseif ( $tag != '#text' ) {
@@ -620,7 +669,14 @@
 		$revision->setTimestamp( $uploadInfo['timestamp'] );
 			   $revision->setText( $text );
 		$revision->setFilename( $uploadInfo['filename'] );
-		$revision->setSrc( $uploadInfo['src'] );
+		/* Pass temp file path for multipart parts */
+		if( substr( $uploadInfo['src'], 0, 12 ) == 'multipart://' )
+		{
+			if ( $p = $this->importSource->parts[ substr( $uploadInfo['src'], 12 ) ] )
+				$revision->setSrc( $p['tempfile'] );
+		}
+		else
+			$revision->setSrc( $uploadInfo['src'] );
 		$revision->setSize( intval( $uploadInfo['size'] ) );
 		$revision->setComment( $uploadInfo['comment'] );
 
@@ -801,6 +857,7 @@
 	var $type = "";
 	var $action = "";
 	var $params = "";
+	var $tempfile = NULL;
 
 	function setTitle( $title ) {
 		if( is_object( $title ) ) {
@@ -849,6 +906,10 @@
 		$this->filename = $filename;
 	}
 
+	function setSha1( $sha1 ) {
+		$this->sha1 = trim( $sha1 );
+	}
+
 	function setSize( $size ) {
 		$this->size = intval( $size );
 	}
@@ -901,6 +962,10 @@
 		return $this->filename;
 	}
 
+	function getSha1() {
+		return $this->sha1;
+	}
+
 	function getSize() {
 		return $this->size;
 	}
@@ -918,6 +983,14 @@
 	}
 
 	function importOldRevision() {
+		# Check edit permission
+		if( !$this->getTitle()->userCan('edit') )
+		{
+			global $wgUser;
+			wfDebug( __METHOD__ . ": edit permission denied for [[" . $this->title->getPrefixedText() . "]], user " . $wgUser->getName() );
+			return false;
+		}
+
 		$dbw = wfGetDB( DB_MASTER );
 
 		# Sneak a single revision into place
@@ -943,7 +1016,7 @@
 		} else {
 			$created = false;
 
-			$prior = $dbw->selectField( 'revision', '1',
+			$prior = $dbw->selectField( 'revision', 'rev_id',
 				array( 'rev_page' => $pageId,
 					'rev_timestamp' => $dbw->timestamp( $this->timestamp ),
 					'rev_user_text' => $userText,
@@ -951,10 +1024,11 @@
 				__METHOD__
 			);
 			if( $prior ) {
+				$prior = Revision::newFromId( $prior );
 				// FIXME: this could fail slightly for multiple matches :P
 				wfDebug( __METHOD__ . ": skipping existing revision for [[" .
 					$this->title->getPrefixedText() . "]], timestamp " . $this->timestamp . "\n" );
-				return false;
+				return $prior;
 			}
 		}
 
@@ -997,7 +1071,9 @@
 		}
 		$GLOBALS['wgTitle'] = $tempTitle;
 
-		return true;
+		# A hack. TOdo it better?
+		$revision->_imported = true;
+		return $revision;
 	}
 
 	function importLogItem() {
@@ -1008,6 +1084,13 @@
 				$this->timestamp . "\n" );
 			return;
 		}
+		# Check edit permission
+		if( !$this->getTitle()->userCan('edit') )
+		{
+			global $wgUser;
+			wfDebug( __METHOD__ . ": edit permission denied for [[" . $this->title->getPrefixedText() . "]], user " . $wgUser->getName() );
+			return false;
+		}
 		# Check if it exists already
 		// FIXME: use original log ID (better for backups)
 		$prior = $dbw->selectField( 'logging', '1',
@@ -1043,30 +1126,17 @@
 		$dbw->insert( 'logging', $data, __METHOD__ );
 	}
 
-	function importUpload() {
-		wfDebug( __METHOD__ . ": STUB\n" );
+	function importUpload()
+	{
+		# Check edit permission
+		if( !$this->getTitle()->userCan('edit') )
+		{
+			global $wgUser;
+			wfDebug( __METHOD__ . ": edit permission denied for [[" . $this->title->getPrefixedText() . "]], user " . $wgUser->getName() );
+			return false;
+		}
 
-		/**
-			// from file revert...
-			$source = $this->file->getArchiveVirtualUrl( $this->oldimage );
-			$comment = $wgRequest->getText( 'wpComment' );
-			// TODO: Preserve file properties from database instead of reloading from file
-			$status = $this->file->upload( $source, $comment, $comment );
-			if( $status->isGood() ) {
-		*/
-
-		/**
-			// from file upload...
-		$this->mLocalFile = wfLocalFile( $nt );
-		$this->mDestName = $this->mLocalFile->getName();
-		//....
-			$status = $this->mLocalFile->upload( $this->mTempPath, $this->mComment, $pageText,
-			File::DELETE_SOURCE, $this->mFileProps );
-			if ( !$status->isGood() ) {
-				$resultDetails = array( 'internal' => $status->getWikiText() );
-		*/
-
-			   // @todo Fixme: it may create a page without our desire, also wrong potentially.
+		// @todo Fixme: it may create a page without our desire, also wrong potentially.
 		// and, it will record a *current* upload, but we might want an archive version here
 
 		$file = wfLocalFile( $this->getTitle() );
@@ -1075,6 +1145,28 @@
 			return false;
 		}
 
+		/* First check if file already exists */
+		if ($file->exists())
+		{
+			/* Backward-compatibility: support export files without sha1 */
+			if ($this->getSha1() && $file->getSha1() == $this->getSha1() ||
+				!$this->getSha1() && $file->getTimestamp() == $this->getTimestamp())
+			{
+				wfDebug( "IMPORT: File already exists and is equal to imported (".$this->getTimestamp().").\n" );
+				return false;
+			}
+			$history = $file->getHistory(null, $this->getTimestamp(), $this->getTimestamp());
+			foreach ($history as $oldfile)
+			{
+				if (!$this->getSha1() || $oldfile->getSha1() == $this->getSha1())
+				{
+					wfDebug( "IMPORT: File revision already exists at its timestamp (".$this->getTimestamp().") and is equal to imported.\n" );
+					return false;
+				}
+			}
+		}
+
+		/* Get file source into a temporary file */
 		$source = $this->downloadSource();
 		if( !$source ) {
 			wfDebug( "IMPORT: Could not fetch remote file. :(\n" );
@@ -1083,21 +1175,38 @@
 
 		$user = User::newFromName( $this->user_text );
 
-		$status = $file->upload( $source,
-			$this->getComment(),
-			$this->getComment(), // Initial page, if none present...
-			File::DELETE_SOURCE,
-			false, // props...
-					   $this->getTimestamp(),
-					   is_object( $user ) ? ( $user->isLoggedIn() ? $user : null ) : null );
+		if ( $file->exists() && $file->getTimestamp() > $this->getTimestamp() )
+		{
+			/* Upload an *archive* version */
+			wfDebug( "Importing an archive $arch version of file (".$this->getTimestamp().")\n" );
+			$status = $file->uploadIntoArchive( $source,
+				$this->getComment(),
+				$this->getComment(), // Initial page, if none present...
+				File::DELETE_SOURCE,
+				false, // props...
+				$this->getTimestamp(),
+				is_object( $user ) ? ( $user->isLoggedIn() ? $user : null ) : null );
+		}
+		else
+		{
+			wfDebug( "Importing a new current version of file (".$this->getTimestamp().")\n" );
+			/* Upload a *current* version */
+			$status = $file->upload( $source,
+				$this->getComment(),
+				$this->getComment(), // Initial page, if none present...
+				File::DELETE_SOURCE,
+				false, // props...
+				$this->getTimestamp(),
+				is_object( $user ) ? ( $user->isLoggedIn() ? $user : null ) : null );
+		}
 
 		if( $status->isGood() ) {
 			// yay?
-			wfDebug( "IMPORT: is ok?\n" );
+			wfDebug( "IMPORT: file imported OK\n" );
 			return true;
 		}
 
-		wfDebug( "IMPORT: is bad? " . $status->getXml() . "\n" );
+		wfDebug( "IMPORT: file import FAILED: " . $status->getXml() . "\n" );
 		return false;
 
 	}
@@ -1108,29 +1217,41 @@
 			return false;
 		}
 
-		$tempo = tempnam( wfTempDir(), 'download' );
-		$f = fopen( $tempo, 'wb' );
+		$src = $this->getSrc();
+		if ( !$src )
+			return false;
+		/* If the file is attached as a part of multipart document, return temp file name */
+		if ( is_file( $src ) )
+			return $src;
+
+		/* If the file is attached as a URL, download it */
+		$this->tempfile = tempnam( wfTempDir(), 'download' );
+		$f = fopen( $this->tempfile, 'wb' );
 		if( !$f ) {
-			wfDebug( "IMPORT: couldn't write to temp file $tempo\n" );
+			wfDebug( "IMPORT: couldn't write to temp file ".$this->tempfile."\n" );
 			return false;
 		}
 
-		// @todo Fixme!
-		$src = $this->getSrc();
+		// @fixme!
 		$data = Http::get( $src );
 		if( !$data ) {
 			wfDebug( "IMPORT: couldn't fetch source $src\n" );
 			fclose( $f );
-			unlink( $tempo );
+			unlink( $this->tempfile );
 			return false;
 		}
 
 		fwrite( $f, $data );
 		fclose( $f );
 
-		return $tempo;
+		return $this->tempfile;
 	}
 
+	function __destruct()
+	{
+		if ( $this->tempfile && is_file( $this->tempfile ) )
+			unlink( $this->tempfile );
+	}
 }
 
 /**
@@ -1155,6 +1276,10 @@
 			return $this->mString;
 		}
 	}
+
+	function nextPart() {
+		return false;
+	}
 }
 
 /**
@@ -1162,20 +1287,131 @@
  * @ingroup SpecialPage
  */
 class ImportStreamSource {
-	function __construct( $handle ) {
+
+	var $buf;
+	var $eop;
+	var $boundary;
+
+	const BUF_SIZE = 65536;
+
+	function __construct( $handle )
+	{
 		$this->mHandle = $handle;
+		$this->eop = false;
+		$this->buf = '';
+		$this->boundary = '';
+		$pos = ftell($this->mHandle);
+		$s = fgets($this->mHandle);
+		/* multipart-related? */
+		if (preg_match("/Content-Type:\s*multipart\/related; boundary=([^\r\n]+)\r*\n/s", $s, $m))
+		{
+			$this->boundary = $m[1];
+			$this->parts = array();
+			/* Unpack multipart document to individual parts.
+			 * The import function must see already downloaded parts.
+			 * But they are dumped AFTER XML part inside the multipart document.
+			 * To be more exact, their position is simply undefined.
+			 */
+			while (!feof($this->mHandle))
+			{
+				$s = trim(fgets($this->mHandle));
+				if ($s != $this->boundary)
+					break;
+				$part = array();
+				/* Read part headers */
+				while ($s != "\n" && $s != "\r\n")
+				{
+					$s = fgets($this->mHandle);
+					if (preg_match('/([a-z0-9\-\_]+):\s*(.*?)\s*$/is', $s, $m))
+						$part[str_replace('-','_',strtolower($m[1]))] = $m[2];
+				}
+				/* Read part data */
+				$tempfile = tempnam(wfTempDir(), "imp");
+				$tempfp = fopen($tempfile, "wb");
+				if (is_numeric($part['content_length']))
+				{
+					$done = 0;
+					$buf = true;
+					while ($done < $part['content_length'] && $buf)
+					{
+						$buf = fread($this->mHandle, min(self::BUF_SIZE, $part['content_length'] - $done));
+						if ($tempfp)
+							fwrite($tempfp, $buf);
+						$done += strlen($buf);
+					}
+				}
+				else
+				{
+					$buf = true;
+					while ($buf)
+					{
+						$buf = fread($this->mHandle, self::BUF_SIZE);
+						if (($p = strpos($buf, "\n".$this->boundary)) !== false)
+						{
+							$pp = ftell($this->mHandle);
+							fseek($this->mHandle, $p+1-strlen($buf), 1);
+							fwrite($tempfp, substr($buf, 0, $p+1));
+							break;
+						}
+						else
+						{
+							/* For the case when $this->boundary crosses the boundary of read buffer */
+							if (strlen($buf) == self::BUF_SIZE &&
+								($p = strrpos($buf, "\n")) !== false)
+							{
+								fseek($this->mHandle, $p+1-self::BUF_SIZE, 1);
+								$buf = substr($buf, 0, $p+1);
+							}
+							fwrite($tempfp, $buf);
+						}
+					}
+				}
+				fclose($tempfp);
+				/* Remember temp file name */
+				$part['tempfile'] = $tempfile;
+				if ($part['content_id'])
+				{
+					$part['sha1'] = File::sha1Base36($part['tempfile']);
+					$this->parts[$part['content_id']] = $part;
+				}
+				else
+					unlink($tempfile);
+			}
+			/* Open XML part for reading */
+			if ($this->parts['Revisions'])
+			{
+				fclose($this->mHandle);
+				$this->mHandle = fopen($this->parts['Revisions']['tempfile'], 'rb');
+			}
+		}
+		/* Else: simply an XML file (not a multipart/related) */
+		else
+			fseek($this->mHandle, $pos, 0);
 	}
 
+	/* Destructor, removes temporary files. */
+	function __destruct()
+	{
+		wfSuppressWarnings();
+		if ($this->mHandle)
+			fclose ($this->mHandle);
+		if ($this->parts)
+			foreach ($this->parts as $part)
+				unlink ($part['tempfile']);
+		wfRestoreWarnings();
+	}
+
 	function atEnd() {
 		return feof( $this->mHandle );
 	}
 
+	/* read next XML part chunk */
 	function readChunk() {
-		return fread( $this->mHandle, 32768 );
+		return fread( $this->mHandle, self::BUF_SIZE );
 	}
 
 	static function newFromFile( $filename ) {
-		$file = @fopen( $filename, 'rt' );
+		$file = @fopen( $filename, 'rb' );
 		if( !$file ) {
 			return Status::newFatal( "importcantopen" );
 		}
Index: languages/messages/MessagesRu.php
===================================================================
--- languages/messages/MessagesRu.php	(revision 85617)
+++ languages/messages/MessagesRu.php	(working copy)
@@ -2719,13 +2719,21 @@
 'exportnohistory'   => "----
 '''Замечание:''' экспорт полной истории изменений страниц отключён из-за проблем с производительностью.",
 'export-submit'     => 'Экспортировать',
-'export-addcattext' => 'Добавить страницы из категории:',
+'export-addpages'   => "'''Добавить страницы:'''",
 'export-addcat'     => 'Добавить',
-'export-addnstext'  => 'Добавить страницы из пространства имён:',
-'export-addns'      => 'Добавить',
+'export-catname'    => 'Категория:',
+'export-modifydate' => 'Изменённые после:',
+'export-namespace'  => 'Пространство имён:',
+'export-invalid-catname' => '<font color=red>\'\'\'Некорректное имя категории проигнорировано: \'$1\'\'\'\'.</font>',
+'export-invalid-namespace' => '<font color=red>\'\'\'Неизвестное пространство имён проигнорировано: \'$1\'\'\'\'.</font>',
+'export-invalid-modifydate' => '<font color=red>\'\'\'Некорректные дата и время проигнорированы (используйте формат <u>YYYY-MM-DD HH:MM:SS</u>): \'$1\'\'\'\'.</font>',
+'export-images'     => 'Экспортировать изображения',
+'export-selfcontained' => 'Включать содержимое изображений в экспортный файл',
 'export-download'   => 'Предложить сохранить как файл',
 'export-templates'  => 'Включить шаблоны',
-'export-pagelinks'  => 'Включить связанные страницы глубиной:',
+'export-pagelinks'  => 'Включить статьи, связанные ссылками',
+'export-closure'    => 'Включая подкатегории',
+'export-link-depth' => 'Максимальная глубина ссылок:',
 
 # Namespace 8 related
 'allmessages'                   => 'Системные сообщения',
@@ -2771,7 +2779,6 @@
 'import-comment'             => 'Примечание:',
 'importtext'                 => 'Пожалуйста, экспортируйте страницу из исходной вики, используя [[Special:Export|соответствующий инструмент]]. Сохраните файл на диск, а затем загрузите его сюда.',
 'importstart'                => 'Импортирование страниц…',
-'import-revision-count'      => '$1 {{PLURAL:$1|версия|версии|версий}}',
 'importnopages'              => 'Нет страниц для импортирования.',
 'imported-log-entries'       => '{{PLURAL:$1|Импортирована $1 запись журнала|Импортировано $1 записи журнала|Импортировано $1 записей журнала}}.',
 'importfailed'               => 'Не удалось импортировать: $1',
@@ -2788,9 +2795,15 @@
 'importuploaderrortemp'      => 'Не удалось загрузить или импортировать файл. Временная папка отсутствует.',
 'import-parse-failure'       => 'Ошибка разбора XML при импорте',
 'import-noarticle'           => 'Нет страницы для импортирования!',
-'import-nonewrevisions'      => 'Все редакции были ранее импортированы.',
 'xml-error-string'           => '$1 в строке $2, позиции $3 (байт $4): $5',
 'import-upload'              => 'Загрузить XML-данные',
+'import-norevisions'         => 'Нет редакций для импортирования.',
+'import-nonewrevisions-localnewer' => 'Все редакции были ранее импортированы. Страница изменена локально.',
+'import-nonewrevisions'      => 'Все редакции были ранее импортированы. Локальных изменений нет.',
+'import-revision-count'      => '$1 {{PLURAL:$1|версия|версии|версий}}.',
+'import-revision-count-newpage' => '$1 {{PLURAL:$1|версия|версии|версий}} (новая страница).',
+'import-conflict'            => '$1 {{PLURAL:$1|версия|версии|версий}} (конфликт: $2).',
+'import-conflict-difflink'   => '$1 (импорт) и $2 (локальная)',
 'import-token-mismatch'      => 'Потеряны данные сеанса. Пожалуйста, попробуйте ещё раз.',
 'import-invalid-interwiki'   => 'Невозможно импортировать из указанной вики.',
 
Index: languages/messages/MessagesEn.php
===================================================================
--- languages/messages/MessagesEn.php	(revision 85617)
+++ languages/messages/MessagesEn.php	(working copy)
@@ -3281,13 +3281,21 @@
 'exportnohistory'   => "----
 '''Note:''' Exporting the full history of pages through this form has been disabled due to performance reasons.",
 'export-submit'     => 'Export',
-'export-addcattext' => 'Add pages from category:',
+'export-addpages'   => "'''Add pages:'''",
 'export-addcat'     => 'Add',
-'export-addnstext'  => 'Add pages from namespace:',
-'export-addns'      => 'Add',
+'export-catname'    => 'Category:',
+'export-modifydate' => 'Changed after:',
+'export-namespace'  => 'Namespace:',
+'export-invalid-catname' => '<font color=red>\'\'\'Unknown category ignored: \'$1\'\'\'\'.</font>',
+'export-invalid-namespace' => '<font color=red>\'\'\'Unknown namespace ignored: \'$1\'\'\'\'.</font>',
+'export-invalid-modifydate' => '<font color=red>\'\'\'Incorrect timestamp ignored (use format <u>YYYY-MM-DD HH:MM:SS</u>): \'$1\'\'\'\'.</font>',
+'export-images'     => 'Export images',
+'export-selfcontained' => 'Include image contents into the export file',
 'export-download'   => 'Save as file',
 'export-templates'  => 'Include templates',
-'export-pagelinks'  => 'Include linked pages to a depth of:',
+'export-pagelinks'  => 'Include linked articles',
+'export-closure'    => 'Include subcategories',
+'export-link-depth' => 'Maximum link depth:',
 
 # Namespace 8 related
 'allmessages'                   => 'System messages',
@@ -3334,7 +3342,6 @@
 'importtext'                 => 'Please export the file from the source wiki using the [[Special:Export|export utility]].
 Save it to your computer and upload it here.',
 'importstart'                => 'Importing pages...',
-'import-revision-count'      => '$1 {{PLURAL:$1|revision|revisions}}',
 'importnopages'              => 'No pages to import.',
 'imported-log-entries'       => 'Imported $1 {{PLURAL:$1|log entry|log entries}}.',
 'importfailed'               => 'Import failed: <nowiki>$1</nowiki>',
@@ -3354,9 +3361,15 @@
 A temporary folder is missing.',
 'import-parse-failure'       => 'XML import parse failure',
 'import-noarticle'           => 'No page to import!',
-'import-nonewrevisions'      => 'All revisions were previously imported.',
 'xml-error-string'           => '$1 at line $2, col $3 (byte $4): $5',
 'import-upload'              => 'Upload XML data',
+'import-norevisions'         => 'No revisions to import.',
+'import-nonewrevisions-localnewer' => 'All revisions were previously imported. Page changed locally.',
+'import-nonewrevisions'      => 'All revisions were previously imported. No local changes.',
+'import-revision-count'      => '$1 {{PLURAL:$1|revision|revisions}}',
+'import-revision-count-newpage' => '$1 {{PLURAL:$1|revision|revisions}} (new page)',
+'import-conflict'            => '$1 {{PLURAL:$1|revision|revisions}} (conflict: $2)',
+'import-conflict-difflink'   => '$1 (imported) и $2 (local)',
 'import-token-mismatch'      => 'Loss of session data.
 Please try again.',
 'import-invalid-interwiki'   => 'Cannot import from the specified wiki.',
